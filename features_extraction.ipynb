{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61cb8b98-4eeb-4fc5-a963-2c208f5de56e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, StratifiedKFold\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import optuna\n",
    "import json\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from catboost import CatBoostClassifier\n",
    "import skl2onnx\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "import traceback\n",
    "import logging\n",
    "\n",
    "#set random seed for reproducibility\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(123)\n",
    "\n",
    "print(\"Random seed set to 123\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280716f-6ff4-46ee-a95e-26647b8f693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set paths\n",
    "metadata_path = \"image_metadata.csv\"\n",
    "split_info_dir = \"splits_info\"\n",
    "splits_dir = \"splits_images\"\n",
    "os.makedirs(split_info_dir, exist_ok=True)\n",
    "os.makedirs(splits_dir, exist_ok=True)\n",
    "\n",
    "#load data\n",
    "df_metadata = pd.read_csv(metadata_path)\n",
    "df_metadata[\"shape\"] = df_metadata[\"shape\"].str.lower().str.strip()\n",
    "image_paths = df_metadata[\"filepath\"].tolist()\n",
    "y = df_metadata[\"defect\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9badf785-62e1-4641-a3bf-25a9a0a37e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution by defect types\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=df_metadata, x=\"defect\", hue=\"defect\", order=df_metadata[\"defect\"].value_counts().index, palette=\"Set2\", legend=False)\n",
    "plt.title(\"Distribution by defect types\")\n",
    "plt.xlabel(\"Defect type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#tablet shapes\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=df_metadata, x=\"shape\", hue=\"shape\", order=df_metadata[\"shape\"].value_counts().index, palette=\"Set2\", legend=False)\n",
    "plt.title(\"Distribution by tablet shapes\")\n",
    "plt.xlabel(\"Shape\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#hatmap of shape vs defect\n",
    "pivot = df_metadata.pivot_table(index=\"shape\", columns=\"defect\", aggfunc=\"size\", fill_value=0)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Count of tablets by shape and defect type\")\n",
    "plt.xlabel(\"Defect type\")\n",
    "plt.ylabel(\"Shape\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#check that customer and defect are converted to strings\n",
    "df_metadata[\"customer\"] = df_metadata[\"customer\"].astype(str)\n",
    "df_metadata[\"defect\"] = df_metadata[\"defect\"].astype(str)\n",
    "df_metadata[\"shape\"] = df_metadata[\"shape\"].astype(str)\n",
    "\n",
    "#select customers\n",
    "for customer in [\"customer1\", \"customer2\"]:\n",
    "    df_customer = df_metadata[df_metadata[\"customer\"].str.lower() == customer.lower()]\n",
    "    \n",
    "    #defect distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.countplot(data=df_customer, x=\"defect\", hue=\"defect\", order=df_customer[\"defect\"].value_counts().index, palette=\"Set2\", legend=False)\n",
    "    plt.title(f\"Defect distribution â€” customer: {customer}\")\n",
    "    plt.xlabel(\"Defect type\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897cb8dc-ee3d-4674-9d44-b9fc405be03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and modify cnn models\n",
    "def get_modified_model(name):\n",
    "    model = getattr(models, name)(weights=getattr(models, f\"{name.split('_')[0].capitalize()}_Weights\").IMAGENET1K_V1)\n",
    "    model.eval().to(device)\n",
    "\n",
    "    if \"resnet\" in name or \"efficientnet\" in name:\n",
    "        model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "    elif \"vgg\" in name:\n",
    "        model.classifier = model.classifier[:-1]\n",
    "    elif \"googlenet\" in name or \"inception\" in name:\n",
    "        model.fc = torch.nn.Identity()\n",
    "    elif \"mobilenet\" in name or \"densenet\" in name:\n",
    "        model.classifier = torch.nn.Identity()\n",
    "    elif any(x in name for x in [\"swin\", \"vit\", \"convnext\"]):\n",
    "        model.head = torch.nn.Identity()\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "#list of cnn model names\n",
    "model_names = [\n",
    "    \"resnet50\", \"resnet101\", \"resnet152\", \"vgg16\", \"vgg19\",\n",
    "    \"efficientnet_b2\", \"efficientnet_b3\", \"googlenet\", \"inception_v3\",\n",
    "    \"mobilenet_v2\", \"mobilenet_v3_large\", \"mobilenet_v3_small\",\n",
    "    \"densenet121\", \"swin_t\", \"vit_b_16\", \"convnext_base\"\n",
    "]\n",
    "\n",
    "#load all cnn models\n",
    "cnn_models = {name: get_modified_model(name) for name in model_names}\n",
    "\n",
    "#define transform (no resizing, images are already 224x224)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#extract features\n",
    "features_dict = {name: [] for name in cnn_models}\n",
    "file_names = []\n",
    "\n",
    "for img_path in tqdm(image_paths, desc=\"processing images\", unit=\"image\"):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        for model_name, model in cnn_models.items():\n",
    "            with torch.no_grad():\n",
    "                feature = model(img_tensor).squeeze().cpu().numpy().flatten()\n",
    "                features_dict[model_name].append(feature)\n",
    "\n",
    "        file_names.append(img_path)\n",
    "    except Exception as e:\n",
    "        print(f\"error processing file {img_path}: {e}\")\n",
    "\n",
    "#save features to csv files\n",
    "for model_name, features in features_dict.items():\n",
    "    df_feat = pd.DataFrame(features)\n",
    "    df_feat.insert(0, \"filename\", file_names)\n",
    "    df_feat.to_csv(f\"features_{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05050b36-314f-48a3-85f9-3075d1abeeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dataset splits\n",
    "splits = {\n",
    "    \"all_data\": df_metadata,\n",
    "    \"customer1\": df_metadata[df_metadata[\"customer\"] == \"customer1\"],\n",
    "    \"customer2\": df_metadata[df_metadata[\"customer\"] == \"customer2\"],\n",
    "    \"oval_round_oblong\": df_metadata[df_metadata[\"shape\"].isin([\"oval\", \"round\", \"oblong\"])],\n",
    "    \"capsules\": df_metadata[df_metadata[\"shape\"] == \"capsule\"],\n",
    "    \"tablets\": df_metadata[df_metadata[\"shape\"] != \"capsule\"],\n",
    "    \"broken\": df_metadata[df_metadata[\"defect\"].isin([\"BROKEN\", \"PROPER\"])],\n",
    "    \"double\": df_metadata[df_metadata[\"defect\"].isin([\"DOUBLE\", \"PROPER\"])],\n",
    "    \"minor_major\": df_metadata[df_metadata[\"defect\"].isin([\"DEFECT_MINOR\", \"DEFECT_MAJOR\", \"PROPER\"])]\n",
    "}\n",
    "\n",
    "#save split info and copy images\n",
    "for split_name, split_df in splits.items():\n",
    "    split_txt_file = os.path.join(split_info_dir, f\"{split_name}.txt\")\n",
    "    split_folder = os.path.join(splits_dir, split_name)\n",
    "    os.makedirs(split_folder, exist_ok=True)\n",
    "\n",
    "    with open(split_txt_file, \"w\") as f:\n",
    "        for path in split_df[\"filepath\"]:\n",
    "            f.write(path + \"\\n\")\n",
    "            shutil.copy(path, os.path.join(split_folder, os.path.basename(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f22565-3b4c-4660-9154-3a888c42b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/val/test splits\n",
    "for split_name, split_df in splits.items():\n",
    "    split_txt_folder = os.path.join(split_info_dir, split_name)\n",
    "    split_image_folder = os.path.join(splits_dir, split_name)\n",
    "\n",
    "    os.makedirs(split_txt_folder, exist_ok=True)\n",
    "    os.makedirs(split_image_folder, exist_ok=True)\n",
    "\n",
    "    #train/validation/test split (70/10/20) \n",
    "    train_df, test_df = train_test_split(split_df, test_size=0.2, random_state=123, stratify=split_df[\"defect\"])\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.125, random_state=123, stratify=train_df[\"defect\"])\n",
    "\n",
    "    #creating train/val/test folders for images\n",
    "    train_txt_file = os.path.join(split_txt_folder, \"train.txt\")\n",
    "    val_txt_file = os.path.join(split_txt_folder, \"val.txt\")\n",
    "    test_txt_file = os.path.join(split_txt_folder, \"test.txt\")\n",
    "\n",
    "    train_folder = os.path.join(split_image_folder, \"train\")\n",
    "    val_folder = os.path.join(split_image_folder, \"val\")\n",
    "    test_folder = os.path.join(split_image_folder, \"test\")\n",
    "\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(val_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "    #saving txt files with paths and copy images\n",
    "    with open(train_txt_file, \"w\") as f_train, open(val_txt_file, \"w\") as f_val, open(test_txt_file, \"w\") as f_test:\n",
    "        for filepath in train_df[\"filepath\"]:\n",
    "            f_train.write(filepath + \"\\n\") \n",
    "            dest_path = os.path.join(train_folder, os.path.basename(filepath))\n",
    "            shutil.copy(filepath, dest_path)  \n",
    "\n",
    "        for filepath in val_df[\"filepath\"]:\n",
    "            f_val.write(filepath + \"\\n\")  \n",
    "            dest_path = os.path.join(val_folder, os.path.basename(filepath))\n",
    "            shutil.copy(filepath, dest_path)  \n",
    "\n",
    "        for filepath in test_df[\"filepath\"]:\n",
    "            f_test.write(filepath + \"\\n\")  \n",
    "            dest_path = os.path.join(test_folder, os.path.basename(filepath))\n",
    "            shutil.copy(filepath, dest_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f8938-cfae-4d39-b111-3406118a4ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads train/val/test filename sets for a given split\n",
    "def load_split_filenames(split_name, base_dir=\"splits_info\"):\n",
    "    base = os.path.join(base_dir, split_name)\n",
    "    with open(os.path.join(base, \"train.txt\")) as f:\n",
    "        train_files = set(f.read().splitlines())\n",
    "    with open(os.path.join(base, \"val.txt\")) as f:\n",
    "        val_files = set(f.read().splitlines())\n",
    "    with open(os.path.join(base, \"test.txt\")) as f:\n",
    "        test_files = set(f.read().splitlines())\n",
    "    return train_files, val_files, test_files\n",
    "\n",
    "#loads feature vectors and corresponding binary labels (0 = proper, 1 = defective)\n",
    "def load_features_and_labels(feature_file, filenames):\n",
    "    # read the feature file and ensure filenames are strings\n",
    "    df = pd.read_csv(feature_file)\n",
    "    df[\"filename\"] = df[\"filename\"].astype(str)\n",
    "    df_subset = df[df[\"filename\"].isin(filenames)]\n",
    "    # X = feature vectors (excluding filename)\n",
    "    X = df_subset.drop(columns=\"filename\").values\n",
    "    # y = labels based on whether filename contains 'proper'\n",
    "    y = np.array([0 if \"proper\" in fn.lower() else 1 for fn in df_subset[\"filename\"]])\n",
    "    return X, y\n",
    "\n",
    "#trains the model and prints precision, recall, and F1-score for class 1\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name=\"Model\"):\n",
    "    print(f\"\\ntraining {model_name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    #compute metrics for class 1 (defective)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    print(f\"{model_name} â†’ precision: {report['1']['precision']:.4f}, recall: {report['1']['recall']:.4f}, f1-score: {report['1']['f1-score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e7a5c1-bdc5-43f5-b0b6-e30a685ebcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all data in split_data\n",
    "split_data = {}\n",
    "split_info_dir = \"splits_info\"\n",
    "feature_files = glob.glob(\"features_*.csv\")\n",
    "\n",
    "for split_name in os.listdir(split_info_dir):\n",
    "    split_path = os.path.join(split_info_dir, split_name)\n",
    "    if not os.path.isdir(split_path):\n",
    "        continue\n",
    "\n",
    "    train_files, val_files, test_files = load_split_filenames(split_name)\n",
    "\n",
    "    for feature_file in feature_files:\n",
    "        model_name = os.path.basename(feature_file).replace(\"features_\", \"\").replace(\".csv\", \"\")\n",
    "\n",
    "        X_train, y_train = load_features_and_labels(feature_file, train_files)\n",
    "        X_val, y_val = load_features_and_labels(feature_file, val_files)\n",
    "        X_test, y_test = load_features_and_labels(feature_file, test_files)\n",
    "\n",
    "        split_data[(split_name, model_name)] = {\n",
    "            \"X_train\": X_train, \"y_train\": y_train,\n",
    "            \"X_val\": X_val, \"y_val\": y_val,\n",
    "            \"X_test\": X_test, \"y_test\": y_test\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7904bd98-4880-4c5a-afdf-32a4bae00b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, max_depth=10, random_state=123, n_jobs=-1),\n",
    "    \"SVM\": SVC(C=1, kernel=\"rbf\"),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,), learning_rate_init=0.01, max_iter=500, random_state=123),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5, weights=\"uniform\"),\n",
    "    \"LogisticRegression\": LogisticRegression(C=1, solver=\"lbfgs\", random_state=123),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, learning_rate=0.1, random_state=123, algorithm=\"SAMME\"),\n",
    "    \"CatBoost\": CatBoostClassifier(iterations=100, learning_rate=0.1, depth=6, verbose=0, random_seed=123, task_type=\"GPU\"),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, verbosity=0, random_state=123, tree_method=\"gpu_hist\", n_jobs=-1),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, verbosity=0, n_jobs=-1, random_state=123)\n",
    "}\n",
    "\n",
    "# use only selected combinations\n",
    "selected_models = [\"convnext_base\", \"resnet50\"]\n",
    "\n",
    "combinations = [\n",
    "    (split_name, model_name)\n",
    "    for (split_name, model_name) in split_data\n",
    "    if model_name in selected_models\n",
    "]\n",
    "\n",
    "metrics_scores = {}\n",
    "\n",
    "for split_name, model_name in combinations:\n",
    "    print(f\"\\n=== running {model_name} on {split_name} ===\")\n",
    "\n",
    "    data = split_data[(split_name, model_name)]\n",
    "    X_train_full = np.vstack((data[\"X_train\"], data[\"X_val\"]))\n",
    "    y_train_full = np.hstack((data[\"y_train\"], data[\"y_val\"]))\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "\n",
    "    for model_label, model in model_params.items():\n",
    "        print(f\"\\ntraining {model_label}\")\n",
    "        model.fit(X_train_full, y_train_full)\n",
    "\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        report = classification_report(y_test, y_test_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "        precision = report[\"1\"][\"precision\"]\n",
    "        recall = report[\"1\"][\"recall\"]\n",
    "        f1 = report[\"1\"][\"f1-score\"]\n",
    "\n",
    "        print(f\"test results for {model_label}:\")\n",
    "        print(f\"precision: {report['1']['precision']:.4f}, recall: {report['1']['recall']:.4f}, f1-score: {report['1']['f1-score']:.4f}\")\n",
    "\n",
    "        #save metrics\n",
    "        key = f\"{model_label}__{split_name}__{model_name}\"\n",
    "        metrics_scores[key] = {\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1\n",
    "        }\n",
    "\n",
    "#save results\n",
    "with open(\"metrics_scores_default.json\", \"w\") as f:\n",
    "    json.dump(metrics_scores, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22badba4-a284-45dc-b0d7-1eea9b222ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#allowed models (feature extractors)\n",
    "allowed_models = [\n",
    "    \"convnext_base\", \"efficientnet_b3\", \"mobilenet_v3_large\",\n",
    "    \"vit_b_16\", \"inception_v3\", \"resnet50\", \"densenet121\", \"resnet152\"\n",
    "]\n",
    "\n",
    "# ml models to tune\n",
    "ml_models = {\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"MLP\": MLPClassifier(max_iter=500, random_state=123),\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=123),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_seed=123),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=123),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=123),\n",
    "}\n",
    "\n",
    "#optuna objective function\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, model_type):\n",
    "    if model_type == \"SVM\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 10, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "        }\n",
    "        model = SVC(**params, probability=True)\n",
    "\n",
    "    elif model_type == \"MLP\":\n",
    "        params = {\n",
    "            \"hidden_layer_sizes\": trial.suggest_categorical(\"hidden_layer_sizes\", [(100,), (50, 50), (200,)]),\n",
    "            \"learning_rate_init\": trial.suggest_float(\"learning_rate_init\", 0.001, 0.1, log=True),\n",
    "        }\n",
    "        model = MLPClassifier(**params, max_iter=500, random_state=123)\n",
    "\n",
    "    elif model_type == \"LogisticRegression\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.01, 10, log=True),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\"]),\n",
    "        }\n",
    "        model = LogisticRegression(**params, random_state=123)\n",
    "\n",
    "    elif model_type == \"XGBoost\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        }\n",
    "        model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "\n",
    "    elif model_type == \"LightGBM\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 60),\n",
    "        }\n",
    "        model = LGBMClassifier(**params, random_state=123)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    best_recall = 0\n",
    "    best_thresh = 0.5\n",
    "    for thresh in np.arange(0.1, 0.91, 0.05):\n",
    "        preds = (probs >= thresh).astype(int)\n",
    "        report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "        recall = report[\"1\"][\"recall\"]\n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            best_thresh = thresh\n",
    "\n",
    "    trial.set_user_attr(\"threshold\", best_thresh)\n",
    "    return best_recall\n",
    "\n",
    "#optimization loop\n",
    "best_params = {}\n",
    "best_models = {}\n",
    "metrics_scores = {}\n",
    "\n",
    "for ml_model_name in ml_models.keys():\n",
    "    best_params[ml_model_name] = {}\n",
    "\n",
    "    for (split_name, model_name), data in split_data.items():\n",
    "        if model_name not in allowed_models:\n",
    "            continue\n",
    "\n",
    "        X_train, y_train = data[\"X_train\"], data[\"y_train\"]\n",
    "        X_val, y_val = data[\"X_val\"], data[\"y_val\"]\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=123))\n",
    "        study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val, ml_model_name), n_trials=15, n_jobs=18)\n",
    "\n",
    "        best_hyperparams = study.best_params\n",
    "        best_thresh = study.best_trial.user_attrs[\"threshold\"]\n",
    "\n",
    "        model = ml_models[ml_model_name].set_params(**best_hyperparams)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        probs = model.predict_proba(X_val)[:, 1]\n",
    "        preds = (probs >= best_thresh).astype(int)\n",
    "        report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "\n",
    "        best_params[ml_model_name][(split_name, model_name)] = {\n",
    "            \"params\": best_hyperparams,\n",
    "            \"threshold\": best_thresh\n",
    "        }\n",
    "\n",
    "        metrics_scores[(ml_model_name, split_name, model_name)] = {\n",
    "            \"recall\": report[\"1\"][\"recall\"],\n",
    "            \"precision\": report[\"1\"][\"precision\"],\n",
    "            \"f1_score\": report[\"1\"][\"f1-score\"]\n",
    "        }\n",
    "\n",
    "        model_path = f\"best_model_{ml_model_name}_{split_name}_{model_name}.pkl\"\n",
    "        joblib.dump(model, model_path)\n",
    "        print(f\"Saved model: {model_path}\")\n",
    "\n",
    "#save results\n",
    "with open(\"metrics_scores_all.json\", \"w\") as f:\n",
    "    json.dump({f\"{k[0]}__{k[1]}__{k[2]}\": v for k, v in metrics_scores.items()}, f, indent=4)\n",
    "\n",
    "with open(\"best_hyperparams_all.json\", \"w\") as f:\n",
    "    json.dump({f\"{model}__{split}__{feat}\": val for model, vals in best_params.items() for (split, feat), val in vals.items()}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb43e8e-5bfb-4791-af02-1121f3ebb81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected models\n",
    "selected_models = [\"convnext_base\", \"efficientnet_b3\", \"mobilenet_v3_large\", \"densenet121\", \"vit_b_16\"]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#model loading\n",
    "model_mapping = {\n",
    "    \"convnext_base\": models.convnext_base(weights=models.ConvNeXt_Base_Weights.IMAGENET1K_V1),\n",
    "    \"efficientnet_b3\": models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1),\n",
    "    \"mobilenet_v3_large\": models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1),\n",
    "    \"densenet121\": models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1),\n",
    "    \"vit_b_16\": models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1),\n",
    "}\n",
    "\n",
    "cnn_models = {}\n",
    "for name in selected_models:\n",
    "    model = model_mapping[name].to(device).eval()\n",
    "    if \"efficientnet\" in name or \"resnet\" in name:\n",
    "        model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "    elif \"vgg\" in name:\n",
    "        model.classifier = model.classifier[:-1]\n",
    "    elif \"googlenet\" in name or \"inception\" in name:\n",
    "        model.fc = torch.nn.Identity()\n",
    "    elif \"mobilenet\" in name or \"densenet\" in name:\n",
    "        model.classifier = torch.nn.Identity()\n",
    "    elif \"swin\" in name or \"vit\" in name or \"convnext\" in name:\n",
    "        model.head = torch.nn.Identity()\n",
    "    cnn_models[name] = model\n",
    "\n",
    "#transforms\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#main loop per split\n",
    "splits_dir = \"splits_info\"\n",
    "for split_name in os.listdir(splits_dir):\n",
    "    split_path = os.path.join(splits_dir, split_name)\n",
    "    if not os.path.isdir(split_path):\n",
    "        continue\n",
    "\n",
    "    sets = {}\n",
    "    for split_type in [\"train\", \"val\", \"test\"]:\n",
    "        with open(os.path.join(split_path, f\"{split_type}.txt\")) as f:\n",
    "            sets[split_type] = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    for split_type, file_list in sets.items():\n",
    "        print(f\"  - {split_type}: {len(file_list)} images\")\n",
    "\n",
    "        transform = aug_transform if split_type == \"train\" else base_transform\n",
    "\n",
    "        features_dict = {name: [] for name in selected_models}\n",
    "        file_names = []\n",
    "\n",
    "        for img_path in tqdm(file_list, desc=f\"{split_type} - {split_name}\", unit=\"img\"):\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "                feature_vectors = []\n",
    "                for model_name, model in cnn_models.items():\n",
    "                    with torch.no_grad():\n",
    "                        feat = model(img_tensor).squeeze().cpu().numpy()\n",
    "                        feature_vectors.append(feat.flatten())\n",
    "\n",
    "                file_names.append(img_path)\n",
    "                for i, model_name in enumerate(selected_models):\n",
    "                    features_dict[model_name].append(feature_vectors[i])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "        #save per model\n",
    "        for model_name, features in features_dict.items():\n",
    "            df_features = pd.DataFrame(features)\n",
    "            df_features.insert(0, \"filename\", file_names)\n",
    "            out_name = f\"features_aug_{split_name}_{model_name}_{split_type}.csv\"\n",
    "            df_features.to_csv(out_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9dbbb-e9c9-492c-ad02-675df36ea598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation\n",
    "#train with data augmentation\n",
    "split_info_dir = \"splits_info\"\n",
    "\n",
    "allowed_models_aug = [\n",
    "    \"convnext_base\", \"efficientnet_b3\", \"mobilenet_v3_large\",\n",
    "    \"densenet121\", \"vit_b_16\"\n",
    "]\n",
    "\n",
    "ml_models = {\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"MLP\": MLPClassifier(max_iter=500, random_state=123),\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=123),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=123),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=123),\n",
    "}\n",
    "\n",
    "#load augmented features\n",
    "print(\"Loading augmented features...\")\n",
    "all_features = {}\n",
    "for file in glob.glob(\"features_aug_*.csv\"):\n",
    "    model_name = file.replace(\"features_aug_\", \"\").replace(\".csv\", \"\")\n",
    "    if model_name in allowed_models_aug:\n",
    "        df = pd.read_csv(file)\n",
    "        df[\"filename\"] = df[\"filename\"].astype(str)\n",
    "        all_features[model_name] = df\n",
    "\n",
    "#load splits\n",
    "print(\"Loading splits...\")\n",
    "split_data = {}\n",
    "for split_name in os.listdir(split_info_dir):\n",
    "    split_path = os.path.join(split_info_dir, split_name)\n",
    "    if not os.path.isdir(split_path):\n",
    "        continue\n",
    "\n",
    "    with open(os.path.join(split_path, \"train.txt\")) as f:\n",
    "        train_files = {line.strip() for line in f}\n",
    "    with open(os.path.join(split_path, \"val.txt\")) as f:\n",
    "        val_files = {line.strip() for line in f}\n",
    "    with open(os.path.join(split_path, \"test.txt\")) as f:\n",
    "        test_files = {line.strip() for line in f}\n",
    "\n",
    "    for model_name, df in all_features.items():\n",
    "        df_train = df[df[\"filename\"].isin(train_files)]\n",
    "        df_val = df[df[\"filename\"].isin(val_files)]\n",
    "        df_test = df[df[\"filename\"].isin(test_files)]\n",
    "\n",
    "        X_train = df_train.drop(columns=[\"filename\"]).values\n",
    "        y_train = [0 if 'proper' in fn.lower() else 1 for fn in df_train[\"filename\"]]\n",
    "\n",
    "        X_val = df_val.drop(columns=[\"filename\"]).values\n",
    "        y_val = [0 if 'proper' in fn.lower() else 1 for fn in df_val[\"filename\"]]\n",
    "\n",
    "        X_test = df_test.drop(columns=[\"filename\"]).values\n",
    "        y_test = [0 if 'proper' in fn.lower() else 1 for fn in df_test[\"filename\"]]\n",
    "\n",
    "        split_data[(split_name, model_name)] = {\n",
    "            \"X_train\": X_train, \"y_train\": y_train,\n",
    "            \"X_val\": X_val, \"y_val\": y_val,\n",
    "            \"X_test\": X_test, \"y_test\": y_test\n",
    "        }\n",
    "\n",
    "#new JSONs to store results\n",
    "metrics_file = \"metrics_scores_aug.json\"\n",
    "params_file = \"best_hyperparams_aug.json\"\n",
    "\n",
    "metrics_scores = {}\n",
    "best_params = {}\n",
    "\n",
    "#optuna objective\n",
    "def objective(trial, X_train, y_train, X_val, y_val, model_type):\n",
    "    if model_type == \"SVM\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 10, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "        }\n",
    "        model = SVC(**params, probability=True)\n",
    "    elif model_type == \"MLP\":\n",
    "        params = {\n",
    "            \"hidden_layer_sizes\": trial.suggest_categorical(\n",
    "                \"hidden_layer_sizes\", [(100,), (50, 50), (200,)]\n",
    "            ),\n",
    "            \"learning_rate_init\": trial.suggest_float(\"learning_rate_init\", 0.001, 0.1, log=True),\n",
    "        }\n",
    "        model = MLPClassifier(**params, max_iter=500, random_state=123)\n",
    "    elif model_type == \"LogisticRegression\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.01, 10, log=True),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\"]),\n",
    "        }\n",
    "        model = LogisticRegression(**params, random_state=123)\n",
    "    elif model_type == \"XGBoost\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        }\n",
    "        model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif model_type == \"LightGBM\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 60),\n",
    "        }\n",
    "        model = LGBMClassifier(**params, random_state=123)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    best_recall, best_thresh = 0, 0.5\n",
    "    for thresh in np.arange(0.1, 0.91, 0.05):\n",
    "        preds = (probs >= thresh).astype(int)\n",
    "        report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "        if report[\"1\"][\"recall\"] > best_recall:\n",
    "            best_recall = report[\"1\"][\"recall\"]\n",
    "            best_thresh = thresh\n",
    "\n",
    "    trial.set_user_attr(\"threshold\", best_thresh)\n",
    "    return best_recall\n",
    "\n",
    "#training function\n",
    "def train_model(ml_model_name, split_name, model_name, data):\n",
    "    key = f\"{ml_model_name}__{split_name}__{model_name}\"\n",
    "    model_path = f\"model_aug_{ml_model_name}_{split_name}_{model_name}.pkl\"\n",
    "\n",
    "    print(f\"\\n[TRAIN] {key}\")\n",
    "    X_train, y_train = data[\"X_train\"], data[\"y_train\"]\n",
    "    X_val, y_val = data[\"X_val\"], data[\"y_val\"]\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=123))\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val, ml_model_name), n_trials=15, n_jobs=18)\n",
    "\n",
    "    best_hyperparams = study.best_params\n",
    "    best_thresh = study.best_trial.user_attrs[\"threshold\"]\n",
    "\n",
    "    model = ml_models[ml_model_name].set_params(**best_hyperparams)\n",
    "    model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_val)[:, 1]\n",
    "    preds = (probs >= best_thresh).astype(int)\n",
    "    report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"[SAVED] {model_path} â†’ F1: {report['1']['f1-score']:.4f}\")\n",
    "\n",
    "    #update dictionaries\n",
    "    metrics_scores[key] = {\n",
    "        \"recall\": report[\"1\"][\"recall\"],\n",
    "        \"precision\": report[\"1\"][\"precision\"],\n",
    "        \"f1_score\": report[\"1\"][\"f1-score\"]\n",
    "    }\n",
    "\n",
    "    if ml_model_name not in best_params:\n",
    "        best_params[ml_model_name] = {}\n",
    "    best_params[ml_model_name][f\"{split_name}__{model_name}\"] = {\n",
    "        \"params\": best_hyperparams,\n",
    "        \"threshold\": best_thresh\n",
    "    }\n",
    "\n",
    "    #save progress\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        json.dump(metrics_scores, f, indent=4)\n",
    "    with open(params_file, \"w\") as f:\n",
    "        json.dump(best_params, f, indent=4)\n",
    "\n",
    "#launch training\n",
    "tasks = []\n",
    "for ml_model_name in ml_models.keys():\n",
    "    for (split_name, model_name), data in split_data.items():\n",
    "        tasks.append((ml_model_name, split_name, model_name, data))\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(train_model, *task) for task in tasks]\n",
    "    for f in futures:\n",
    "        f.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7752c4a-a6f8-4e17-a1f3-d95d4a9af2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling 1:1\n",
    "logging.basicConfig(filename=\"train_log_down.txt\", level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "splits = [\n",
    "    \"customer1\", \"all_data\", \"broken\", \"capsules\", \"customer2\",\n",
    "    \"double\", \"minor_major\", \"oval_round_oblong\", \"tablets\"\n",
    "]\n",
    "allowed_models = [\n",
    "    \"convnext_base\", \"efficientnet_b3\", \"mobilenet_v3_large\",\n",
    "    \"vit_b_16\", \"densenet121\"\n",
    "]\n",
    "ordered_ml_models = [\"MLP\", \"LogisticRegression\", \"XGBoost\", \"LightGBM\", \"SVM\"]\n",
    "split_info_dir = \"splits_info\"\n",
    "\n",
    "def get_model_instance(name):\n",
    "    if name == \"SVM\":\n",
    "        return SVC(probability=True)\n",
    "    elif name == \"MLP\":\n",
    "        return MLPClassifier(max_iter=500, random_state=123)\n",
    "    elif name == \"LogisticRegression\":\n",
    "        return LogisticRegression(random_state=123)\n",
    "    elif name == \"XGBoost\":\n",
    "        return XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif name == \"LightGBM\":\n",
    "        return LGBMClassifier(random_state=123)\n",
    "\n",
    "def convert_for_json(obj):\n",
    "    return list(obj) if isinstance(obj, tuple) else obj\n",
    "\n",
    "def save_jsons():\n",
    "    with open(\"metrics_scores_down.json\", \"w\") as f:\n",
    "        json.dump(metrics_scores, f, indent=4)\n",
    "    with open(\"best_hyperparams_down.json\", \"w\") as f:\n",
    "        json.dump(best_params, f, indent=4, default=convert_for_json)\n",
    "\n",
    "def find_best_threshold(y_true, probs):\n",
    "    best_recall = 0\n",
    "    best_thresh = 0.5\n",
    "    for thresh in np.arange(0.1, 0.91, 0.05):\n",
    "        preds = (probs >= thresh).astype(int)\n",
    "        report = classification_report(y_true, preds, output_dict=True, zero_division=0)\n",
    "        recall = report[\"1\"][\"recall\"]\n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            best_thresh = thresh\n",
    "    return best_thresh\n",
    "\n",
    "def apply_downsampling(X, y):\n",
    "    df = X.copy()\n",
    "    df[\"label\"] = y\n",
    "    df_major = df[df[\"label\"] == 0]\n",
    "    df_minor = df[df[\"label\"] == 1]\n",
    "    df_major_down = resample(df_major, replace=False, n_samples=len(df_minor), random_state=123)\n",
    "    df_balanced = pd.concat([df_major_down, df_minor]).sample(frac=1, random_state=123)\n",
    "    y_balanced = df_balanced[\"label\"].values\n",
    "    X_balanced = df_balanced.drop(columns=[\"label\"]).values\n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "#load features\n",
    "print(\"Loading features...\")\n",
    "all_features = {}\n",
    "for model_name in allowed_models:\n",
    "    path = f\"features_{model_name}.csv\"\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        df[\"filename\"] = df[\"filename\"].astype(str)\n",
    "        all_features[model_name] = df\n",
    "    else:\n",
    "        logging.warning(f\"Missing features: {path}\")\n",
    "\n",
    "#split_data\n",
    "split_data = {}\n",
    "for split in splits:\n",
    "    split_path = os.path.join(split_info_dir, split)\n",
    "    try:\n",
    "        with open(os.path.join(split_path, \"train.txt\")) as f:\n",
    "            train_files = {line.strip() for line in f}\n",
    "        with open(os.path.join(split_path, \"val.txt\")) as f:\n",
    "            val_files = {line.strip() for line in f}\n",
    "        with open(os.path.join(split_path, \"test.txt\")) as f:\n",
    "            test_files = {line.strip() for line in f}\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Skipping split {split}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "    for model_name, df in all_features.items():\n",
    "        df_train = df[df[\"filename\"].isin(train_files)]\n",
    "        df_val = df[df[\"filename\"].isin(val_files)]\n",
    "        df_test = df[df[\"filename\"].isin(test_files)]\n",
    "\n",
    "        X_train = df_train.drop(columns=[\"filename\"])\n",
    "        y_train = [0 if \"proper\" in fn.lower() else 1 for fn in df_train[\"filename\"]]\n",
    "\n",
    "        X_val = df_val.drop(columns=[\"filename\"])\n",
    "        y_val = [0 if \"proper\" in fn.lower() else 1 for fn in df_val[\"filename\"]]\n",
    "\n",
    "        X_test = df_test.drop(columns=[\"filename\"])\n",
    "        y_test = [0 if \"proper\" in fn.lower() else 1 for fn in df_test[\"filename\"]]\n",
    "\n",
    "        split_data[(split, model_name)] = {\n",
    "            \"X_train\": X_train, \"y_train\": y_train,\n",
    "            \"X_val\": X_val, \"y_val\": y_val,\n",
    "            \"X_test\": X_test, \"y_test\": y_test\n",
    "        }\n",
    "\n",
    "#load jsons \n",
    "metrics_scores = json.load(open(\"metrics_scores_down.json\")) if os.path.exists(\"metrics_scores_down.json\") else {}\n",
    "best_params = json.load(open(\"best_hyperparams_down.json\")) if os.path.exists(\"best_hyperparams_down.json\") else {}\n",
    "\n",
    "#objective function \n",
    "def objective(trial, X_train, y_train, X_val, y_val, model_type):\n",
    "    if model_type == \"SVM\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 10, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "        }\n",
    "        model = SVC(**params, probability=True)\n",
    "    elif model_type == \"MLP\":\n",
    "        choice = trial.suggest_categorical(\"hidden_layer_sizes\", [\"100\", \"50_50\", \"200\"])\n",
    "        mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "        params = {\n",
    "            \"hidden_layer_sizes\": mapping[choice],\n",
    "            \"learning_rate_init\": trial.suggest_float(\"learning_rate_init\", 0.001, 0.1, log=True)\n",
    "        }\n",
    "        model = MLPClassifier(**params, max_iter=500, random_state=123)\n",
    "    elif model_type == \"LogisticRegression\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.01, 10, log=True),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\"]),\n",
    "        }\n",
    "        model = LogisticRegression(**params, random_state=123)\n",
    "    elif model_type == \"XGBoost\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        }\n",
    "        model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif model_type == \"LightGBM\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 60),\n",
    "        }\n",
    "        model = LGBMClassifier(**params, random_state=123)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_val)[:, 1]\n",
    "    best_thresh = find_best_threshold(y_val, probs)\n",
    "    preds = (probs >= best_thresh).astype(int)\n",
    "    report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "    trial.set_user_attr(\"threshold\", best_thresh)\n",
    "    return report[\"1\"][\"f1-score\"]\n",
    "\n",
    "#training wrapper\n",
    "def process_combination(ml_model_name, split_name, model_name, data):\n",
    "    key_json = f\"{ml_model_name}__{split_name}__{model_name}\"\n",
    "    model_path = f\"model_down_{ml_model_name}_{split_name}_{model_name}.pkl\"\n",
    "    try:\n",
    "        logging.info(f\"[TRAINING] {key_json}\")\n",
    "        X_train, y_train = apply_downsampling(data[\"X_train\"], data[\"y_train\"])\n",
    "        X_val, y_val = data[\"X_val\"], data[\"y_val\"]\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=123))\n",
    "        study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val, ml_model_name), n_trials=15, n_jobs=18)\n",
    "        best_hyperparams = study.best_params\n",
    "        best_thresh = study.best_trial.user_attrs[\"threshold\"]\n",
    "\n",
    "        if ml_model_name == \"MLP\" and isinstance(best_hyperparams.get(\"hidden_layer_sizes\"), str):\n",
    "            mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "            best_hyperparams[\"hidden_layer_sizes\"] = mapping[best_hyperparams[\"hidden_layer_sizes\"]]\n",
    "\n",
    "        model = get_model_instance(ml_model_name)\n",
    "        model.set_params(**best_hyperparams)\n",
    "        model.fit(X_train, y_train)\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "        probs = model.predict_proba(X_val)[:, 1]\n",
    "        preds = (probs >= best_thresh).astype(int)\n",
    "        report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "\n",
    "        metrics_scores[key_json] = {\n",
    "            \"recall\": report[\"1\"][\"recall\"],\n",
    "            \"precision\": report[\"1\"][\"precision\"],\n",
    "            \"f1_score\": report[\"1\"][\"f1-score\"]\n",
    "        }\n",
    "\n",
    "        if ml_model_name not in best_params:\n",
    "            best_params[ml_model_name] = {}\n",
    "        best_params[ml_model_name][f\"{split_name}__{model_name}\"] = {\n",
    "            \"params\": best_hyperparams,\n",
    "            \"threshold\": float(best_thresh)\n",
    "        }\n",
    "\n",
    "        save_jsons()\n",
    "        logging.info(f\"[DONE] {key_json} with F1: {report['1']['f1-score']:.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[ERROR] {key_json} failed: {str(e)}\")\n",
    "        logging.error(traceback.format_exc())\n",
    "\n",
    "#training \n",
    "tasks = [(ml, split, model, split_data[(split, model)])\n",
    "         for ml in ordered_ml_models for (split, model) in split_data]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(process_combination, *task) for task in tasks]\n",
    "    for future in as_completed(futures):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de24de-0230-4bbf-a64a-43bfa234b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsampling 1:3\n",
    "logging.basicConfig(filename=\"train_log_down3.txt\", level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "splits = [\n",
    "    \"customer1\", \"all_data\", \"broken\", \"capsules\", \"customer2\",\n",
    "    \"double\", \"minor_major\", \"oval_round_oblong\", \"tablets\"\n",
    "]\n",
    "allowed_models = [\n",
    "    \"convnext_base\", \"efficientnet_b3\", \"mobilenet_v3_large\",\n",
    "    \"vit_b_16\", \"densenet121\"\n",
    "]\n",
    "ordered_ml_models = [\"MLP\", \"LogisticRegression\", \"XGBoost\", \"LightGBM\", \"SVM\"]\n",
    "split_info_dir = \"splits_info\"\n",
    "\n",
    "def get_model_instance(name):\n",
    "    if name == \"SVM\":\n",
    "        return SVC(probability=True)\n",
    "    elif name == \"MLP\":\n",
    "        return MLPClassifier(max_iter=500, random_state=123)\n",
    "    elif name == \"LogisticRegression\":\n",
    "        return LogisticRegression(random_state=123)\n",
    "    elif name == \"XGBoost\":\n",
    "        return XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif name == \"LightGBM\":\n",
    "        return LGBMClassifier(random_state=123)\n",
    "\n",
    "def convert_for_json(obj):\n",
    "    return list(obj) if isinstance(obj, tuple) else obj\n",
    "\n",
    "def save_jsons():\n",
    "    with open(\"metrics_scores_down3.json\", \"w\") as f:\n",
    "        json.dump(metrics_scores, f, indent=4)\n",
    "    with open(\"best_hyperparams_down3.json\", \"w\") as f:\n",
    "        json.dump(best_params, f, indent=4, default=convert_for_json)\n",
    "\n",
    "def find_best_threshold(y_true, probs):\n",
    "    best_recall = 0\n",
    "    best_thresh = 0.5\n",
    "    for thresh in np.arange(0.1, 0.91, 0.05):\n",
    "        preds = (probs >= thresh).astype(int)\n",
    "        report = classification_report(y_true, preds, output_dict=True, zero_division=0)\n",
    "        recall = report[\"1\"][\"recall\"]\n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            best_thresh = thresh\n",
    "    return best_thresh\n",
    "\n",
    "def apply_downsampling(X, y):\n",
    "    df = X.copy()\n",
    "    df[\"label\"] = y\n",
    "    df_major = df[df[\"label\"] == 0]\n",
    "    df_minor = df[df[\"label\"] == 1]\n",
    "    n_samples = min(len(df_major), 3 * len(df_minor))\n",
    "    df_major_down = resample(df_major, replace=False, n_samples=n_samples, random_state=123)\n",
    "    df_balanced = pd.concat([df_major_down, df_minor]).sample(frac=1, random_state=123)\n",
    "    y_balanced = df_balanced[\"label\"].values\n",
    "    X_balanced = df_balanced.drop(columns=[\"label\"]).values\n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "#load features\n",
    "all_features = {}\n",
    "for model_name in allowed_models:\n",
    "    path = f\"features_{model_name}.csv\"\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        df[\"filename\"] = df[\"filename\"].astype(str)\n",
    "        all_features[model_name] = df\n",
    "    else:\n",
    "        logging.warning(f\"Missing features: {path}\")\n",
    "\n",
    "#split_data\n",
    "split_data = {}\n",
    "for split in splits:\n",
    "    split_path = os.path.join(split_info_dir, split)\n",
    "    try:\n",
    "        with open(os.path.join(split_path, \"train.txt\")) as f:\n",
    "            train_files = {line.strip() for line in f}\n",
    "        with open(os.path.join(split_path, \"val.txt\")) as f:\n",
    "            val_files = {line.strip() for line in f}\n",
    "        with open(os.path.join(split_path, \"test.txt\")) as f:\n",
    "            test_files = {line.strip() for line in f}\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Skipping split {split}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "    for model_name, df in all_features.items():\n",
    "        df_train = df[df[\"filename\"].isin(train_files)]\n",
    "        df_val = df[df[\"filename\"].isin(val_files)]\n",
    "        df_test = df[df[\"filename\"].isin(test_files)]\n",
    "\n",
    "        X_train = df_train.drop(columns=[\"filename\"])\n",
    "        y_train = [0 if \"proper\" in fn.lower() else 1 for fn in df_train[\"filename\"]]\n",
    "\n",
    "        X_val = df_val.drop(columns=[\"filename\"])\n",
    "        y_val = [0 if \"proper\" in fn.lower() else 1 for fn in df_val[\"filename\"]]\n",
    "\n",
    "        X_test = df_test.drop(columns=[\"filename\"])\n",
    "        y_test = [0 if \"proper\" in fn.lower() else 1 for fn in df_test[\"filename\"]]\n",
    "\n",
    "        split_data[(split, model_name)] = {\n",
    "            \"X_train\": X_train, \"y_train\": y_train,\n",
    "            \"X_val\": X_val, \"y_val\": y_val,\n",
    "            \"X_test\": X_test, \"y_test\": y_test\n",
    "        }\n",
    "\n",
    "#load jsons\n",
    "metrics_scores = json.load(open(\"metrics_scores_down3.json\")) if os.path.exists(\"metrics_scores_down3.json\") else {}\n",
    "best_params = json.load(open(\"best_hyperparams_down3.json\")) if os.path.exists(\"best_hyperparams_down3.json\") else {}\n",
    "\n",
    "#objective function\n",
    "def objective(trial, X_train, y_train, X_val, y_val, model_type):\n",
    "    if model_type == \"SVM\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 10, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "        }\n",
    "        model = SVC(**params, probability=True)\n",
    "    elif model_type == \"MLP\":\n",
    "        choice = trial.suggest_categorical(\"hidden_layer_sizes\", [\"100\", \"50_50\", \"200\"])\n",
    "        mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "        params = {\n",
    "            \"hidden_layer_sizes\": mapping[choice],\n",
    "            \"learning_rate_init\": trial.suggest_float(\"learning_rate_init\", 0.001, 0.1, log=True)\n",
    "        }\n",
    "        model = MLPClassifier(**params, max_iter=500, random_state=123)\n",
    "    elif model_type == \"LogisticRegression\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.01, 10, log=True),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\"]),\n",
    "        }\n",
    "        model = LogisticRegression(**params, random_state=123)\n",
    "    elif model_type == \"XGBoost\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        }\n",
    "        model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif model_type == \"LightGBM\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 60),\n",
    "        }\n",
    "        model = LGBMClassifier(**params, random_state=123)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_val)[:, 1]\n",
    "    best_thresh = find_best_threshold(y_val, probs)\n",
    "    preds = (probs >= best_thresh).astype(int)\n",
    "    report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "    trial.set_user_attr(\"threshold\", best_thresh)\n",
    "    return report[\"1\"][\"f1-score\"]\n",
    "\n",
    "#training wrapper\n",
    "def process_combination(ml_model_name, split_name, model_name, data):\n",
    "    key_json = f\"{ml_model_name}__{split_name}__{model_name}\"\n",
    "    model_path = f\"model_down3_{ml_model_name}_{split_name}_{model_name}.pkl\"\n",
    "    try:\n",
    "        logging.info(f\"[TRAINING] {key_json}\")\n",
    "        X_train, y_train = apply_downsampling(data[\"X_train\"], data[\"y_train\"])\n",
    "        X_val, y_val = data[\"X_val\"], data[\"y_val\"]\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=123))\n",
    "        study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val, ml_model_name), n_trials=15, n_jobs=18)\n",
    "        best_hyperparams = study.best_params\n",
    "        best_thresh = study.best_trial.user_attrs[\"threshold\"]\n",
    "\n",
    "        if ml_model_name == \"MLP\" and isinstance(best_hyperparams.get(\"hidden_layer_sizes\"), str):\n",
    "            mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "            best_hyperparams[\"hidden_layer_sizes\"] = mapping[best_hyperparams[\"hidden_layer_sizes\"]]\n",
    "\n",
    "        model = get_model_instance(ml_model_name)\n",
    "        model.set_params(**best_hyperparams)\n",
    "        model.fit(X_train, y_train)\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "        probs = model.predict_proba(X_val)[:, 1]\n",
    "        preds = (probs >= best_thresh).astype(int)\n",
    "        report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "\n",
    "        metrics_scores[key_json] = {\n",
    "            \"recall\": report[\"1\"][\"recall\"],\n",
    "            \"precision\": report[\"1\"][\"precision\"],\n",
    "            \"f1_score\": report[\"1\"][\"f1-score\"]\n",
    "        }\n",
    "\n",
    "        if ml_model_name not in best_params:\n",
    "            best_params[ml_model_name] = {}\n",
    "        best_params[ml_model_name][f\"{split_name}__{model_name}\"] = {\n",
    "            \"params\": best_hyperparams,\n",
    "            \"threshold\": float(best_thresh)\n",
    "        }\n",
    "\n",
    "        save_jsons()\n",
    "        logging.info(f\"[DONE] {key_json} with F1: {report['1']['f1-score']:.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[ERROR] {key_json} failed: {str(e)}\")\n",
    "        logging.error(traceback.format_exc())\n",
    "\n",
    "#training\n",
    "tasks = [(ml, split, model, split_data[(split, model)])\n",
    "         for ml in ordered_ml_models for (split, model) in split_data]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(process_combination, *task) for task in tasks]\n",
    "    for future in as_completed(futures):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a7038-4cf8-490b-af03-8aed218a7651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsampling 1:5\n",
    "logging.basicConfig(filename=\"train_log_down5.txt\", level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "splits = [\n",
    "    \"customer1\", \"all_data\", \"broken\", \"capsules\", \"customer2\",\n",
    "    \"double\", \"minor_major\", \"oval_round_oblong\", \"tablets\"\n",
    "]\n",
    "allowed_models = [\n",
    "    \"convnext_base\", \"efficientnet_b3\", \"mobilenet_v3_large\",\n",
    "    \"vit_b_16\", \"densenet121\"\n",
    "]\n",
    "ordered_ml_models = [\"MLP\", \"LogisticRegression\", \"XGBoost\", \"LightGBM\", \"SVM\"]\n",
    "split_info_dir = \"splits_info\"\n",
    "\n",
    "def get_model_instance(name):\n",
    "    if name == \"SVM\":\n",
    "        return SVC(probability=True)\n",
    "    elif name == \"MLP\":\n",
    "        return MLPClassifier(max_iter=500, random_state=123)\n",
    "    elif name == \"LogisticRegression\":\n",
    "        return LogisticRegression(random_state=123)\n",
    "    elif name == \"XGBoost\":\n",
    "        return XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif name == \"LightGBM\":\n",
    "        return LGBMClassifier(random_state=123)\n",
    "\n",
    "def convert_for_json(obj):\n",
    "    return list(obj) if isinstance(obj, tuple) else obj\n",
    "\n",
    "def save_jsons():\n",
    "    with open(\"metrics_scores_down5.json\", \"w\") as f:\n",
    "        json.dump(metrics_scores, f, indent=4)\n",
    "    with open(\"best_hyperparams_down5.json\", \"w\") as f:\n",
    "        json.dump(best_params, f, indent=4, default=convert_for_json)\n",
    "\n",
    "def find_best_threshold(y_true, probs):\n",
    "    best_recall = 0\n",
    "    best_thresh = 0.5\n",
    "    for thresh in np.arange(0.1, 0.91, 0.05):\n",
    "        preds = (probs >= thresh).astype(int)\n",
    "        report = classification_report(y_true, preds, output_dict=True, zero_division=0)\n",
    "        recall = report[\"1\"][\"recall\"]\n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            best_thresh = thresh\n",
    "    return best_thresh\n",
    "\n",
    "def apply_downsampling(X, y):\n",
    "    df = X.copy()\n",
    "    df[\"label\"] = y\n",
    "    df_major = df[df[\"label\"] == 0]\n",
    "    df_minor = df[df[\"label\"] == 1]\n",
    "    n_samples = min(len(df_major), 5 * len(df_minor))\n",
    "    df_major_down = resample(df_major, replace=False, n_samples=n_samples, random_state=123)\n",
    "    df_balanced = pd.concat([df_major_down, df_minor]).sample(frac=1, random_state=123)\n",
    "    y_balanced = df_balanced[\"label\"].values\n",
    "    X_balanced = df_balanced.drop(columns=[\"label\"]).values\n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "#load features\n",
    "all_features = {}\n",
    "for model_name in allowed_models:\n",
    "    path = f\"features_{model_name}.csv\"\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        df[\"filename\"] = df[\"filename\"].astype(str)\n",
    "        all_features[model_name] = df\n",
    "    else:\n",
    "        logging.warning(f\"Missing features: {path}\")\n",
    "\n",
    "#split_data \n",
    "split_data = {}\n",
    "for split in splits:\n",
    "    split_path = os.path.join(split_info_dir, split)\n",
    "    try:\n",
    "        with open(os.path.join(split_path, \"train.txt\")) as f:\n",
    "            train_files = {line.strip() for line in f}\n",
    "        with open(os.path.join(split_path, \"val.txt\")) as f:\n",
    "            val_files = {line.strip() for line in f}\n",
    "        with open(os.path.join(split_path, \"test.txt\")) as f:\n",
    "            test_files = {line.strip() for line in f}\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Skipping split {split}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "    for model_name, df in all_features.items():\n",
    "        df_train = df[df[\"filename\"].isin(train_files)]\n",
    "        df_val = df[df[\"filename\"].isin(val_files)]\n",
    "        df_test = df[df[\"filename\"].isin(test_files)]\n",
    "\n",
    "        X_train = df_train.drop(columns=[\"filename\"])\n",
    "        y_train = [0 if \"proper\" in fn.lower() else 1 for fn in df_train[\"filename\"]]\n",
    "\n",
    "        X_val = df_val.drop(columns=[\"filename\"])\n",
    "        y_val = [0 if \"proper\" in fn.lower() else 1 for fn in df_val[\"filename\"]]\n",
    "\n",
    "        X_test = df_test.drop(columns=[\"filename\"])\n",
    "        y_test = [0 if \"proper\" in fn.lower() else 1 for fn in df_test[\"filename\"]]\n",
    "\n",
    "        split_data[(split, model_name)] = {\n",
    "            \"X_train\": X_train, \"y_train\": y_train,\n",
    "            \"X_val\": X_val, \"y_val\": y_val,\n",
    "            \"X_test\": X_test, \"y_test\": y_test\n",
    "        }\n",
    "\n",
    "#load jsons\n",
    "metrics_scores = json.load(open(\"metrics_scores_down5.json\")) if os.path.exists(\"metrics_scores_down5.json\") else {}\n",
    "best_params = json.load(open(\"best_hyperparams_down5.json\")) if os.path.exists(\"best_hyperparams_down5.json\") else {}\n",
    "\n",
    "#objective function\n",
    "def objective(trial, X_train, y_train, X_val, y_val, model_type):\n",
    "    if model_type == \"SVM\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 10, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "        }\n",
    "        model = SVC(**params, probability=True)\n",
    "    elif model_type == \"MLP\":\n",
    "        choice = trial.suggest_categorical(\"hidden_layer_sizes\", [\"100\", \"50_50\", \"200\"])\n",
    "        mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "        params = {\n",
    "            \"hidden_layer_sizes\": mapping[choice],\n",
    "            \"learning_rate_init\": trial.suggest_float(\"learning_rate_init\", 0.001, 0.1, log=True)\n",
    "        }\n",
    "        model = MLPClassifier(**params, max_iter=500, random_state=123)\n",
    "    elif model_type == \"LogisticRegression\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.01, 10, log=True),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\"]),\n",
    "        }\n",
    "        model = LogisticRegression(**params, random_state=123)\n",
    "    elif model_type == \"XGBoost\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        }\n",
    "        model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif model_type == \"LightGBM\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 60),\n",
    "        }\n",
    "        model = LGBMClassifier(**params, random_state=123)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_val)[:, 1]\n",
    "    best_thresh = find_best_threshold(y_val, probs)\n",
    "    preds = (probs >= best_thresh).astype(int)\n",
    "    report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "    trial.set_user_attr(\"threshold\", best_thresh)\n",
    "    return report[\"1\"][\"f1-score\"]\n",
    "\n",
    "#training wrapper\n",
    "def process_combination(ml_model_name, split_name, model_name, data):\n",
    "    key_json = f\"{ml_model_name}__{split_name}__{model_name}\"\n",
    "    model_path = f\"model_down5_{ml_model_name}_{split_name}_{model_name}.pkl\"\n",
    "    try:\n",
    "        logging.info(f\"[TRAINING] {key_json}\")\n",
    "        X_train, y_train = apply_downsampling(data[\"X_train\"], data[\"y_train\"])\n",
    "        X_val, y_val = data[\"X_val\"], data[\"y_val\"]\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=123))\n",
    "        study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val, ml_model_name), n_trials=15, n_jobs=18)\n",
    "        best_hyperparams = study.best_params\n",
    "        best_thresh = study.best_trial.user_attrs[\"threshold\"]\n",
    "\n",
    "        if ml_model_name == \"MLP\" and isinstance(best_hyperparams.get(\"hidden_layer_sizes\"), str):\n",
    "            mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "            best_hyperparams[\"hidden_layer_sizes\"] = mapping[best_hyperparams[\"hidden_layer_sizes\"]]\n",
    "\n",
    "        model = get_model_instance(ml_model_name)\n",
    "        model.set_params(**best_hyperparams)\n",
    "        model.fit(X_train, y_train)\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "        probs = model.predict_proba(X_val)[:, 1]\n",
    "        preds = (probs >= best_thresh).astype(int)\n",
    "        report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "\n",
    "        metrics_scores[key_json] = {\n",
    "            \"recall\": report[\"1\"][\"recall\"],\n",
    "            \"precision\": report[\"1\"][\"precision\"],\n",
    "            \"f1_score\": report[\"1\"][\"f1-score\"]\n",
    "        }\n",
    "\n",
    "        if ml_model_name not in best_params:\n",
    "            best_params[ml_model_name] = {}\n",
    "        best_params[ml_model_name][f\"{split_name}__{model_name}\"] = {\n",
    "            \"params\": best_hyperparams,\n",
    "            \"threshold\": float(best_thresh)\n",
    "        }\n",
    "\n",
    "        save_jsons()\n",
    "        logging.info(f\"[DONE] {key_json} with F1: {report['1']['f1-score']:.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[ERROR] {key_json} failed: {str(e)}\")\n",
    "        logging.error(traceback.format_exc())\n",
    "\n",
    "#training \n",
    "tasks = [(ml, split, model, split_data[(split, model)])\n",
    "         for ml in ordered_ml_models for (split, model) in split_data]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(process_combination, *task) for task in tasks]\n",
    "    for future in as_completed(futures):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621e5e3-dfab-4775-aa36-c8699c454292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsampling 1:1 + data augmentation\n",
    "log_file = \"train_log_aug_down.txt\"\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "splits = [\n",
    "    \"customer1\", \"all_data\", \"broken\", \"capsules\", \"customer2\",\n",
    "    \"double\", \"minor_major\", \"oval_round_oblong\", \"tablets\"\n",
    "]\n",
    "allowed_models = [\n",
    "    \"convnext_base\", \"efficientnet_b3\", \"mobilenet_v3_large\",\n",
    "    \"vit_b_16\", \"densenet121\"\n",
    "]\n",
    "ml_model_names = [\"MLP\", \"LogisticRegression\", \"XGBoost\", \"LightGBM\", \"SVM\"]\n",
    "\n",
    "def get_model_instance(name):\n",
    "    if name == \"SVM\":\n",
    "        return SVC(probability=True)\n",
    "    elif name == \"MLP\":\n",
    "        return MLPClassifier(max_iter=500, random_state=123)\n",
    "    elif name == \"LogisticRegression\":\n",
    "        return LogisticRegression(random_state=123)\n",
    "    elif name == \"XGBoost\":\n",
    "        return XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif name == \"LightGBM\":\n",
    "        return LGBMClassifier(random_state=123)\n",
    "\n",
    "def load_json(path):\n",
    "    return json.load(open(path)) if os.path.exists(path) else {}\n",
    "\n",
    "def convert_for_json(obj):\n",
    "    return list(obj) if isinstance(obj, tuple) else obj\n",
    "\n",
    "def save_jsons():\n",
    "    with open(\"metrics_scores_aug_down.json\", \"w\") as f:\n",
    "        json.dump(metrics_scores, f, indent=4)\n",
    "    with open(\"best_hyperparams_aug_down.json\", \"w\") as f:\n",
    "        json.dump(best_params, f, indent=4, default=convert_for_json)\n",
    "\n",
    "def find_best_threshold(y_true, probs):\n",
    "    best_recall = 0\n",
    "    best_thresh = 0.5\n",
    "    for thresh in np.arange(0.1, 0.91, 0.05):\n",
    "        preds = (probs >= thresh).astype(int)\n",
    "        report = classification_report(y_true, preds, output_dict=True, zero_division=0)\n",
    "        recall = report[\"1\"][\"recall\"]\n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            best_thresh = thresh\n",
    "    return best_thresh\n",
    "\n",
    "def apply_downsampling(X, y):\n",
    "    df = X.copy()\n",
    "    df[\"label\"] = y\n",
    "    df_major = df[df[\"label\"] == 0]\n",
    "    df_minor = df[df[\"label\"] == 1]\n",
    "    df_major_down = resample(df_major, replace=False, n_samples=len(df_minor), random_state=123)\n",
    "    df_balanced = pd.concat([df_major_down, df_minor]).sample(frac=1, random_state=123)\n",
    "    y_balanced = df_balanced[\"label\"].values\n",
    "    X_balanced = df_balanced.drop(columns=[\"label\"]).values\n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "#load features\n",
    "split_data = {}\n",
    "for split in splits:\n",
    "    for model_name in allowed_models:\n",
    "        try:\n",
    "            df_train = pd.read_csv(f\"features_aug_{split}_{model_name}_train.csv\")\n",
    "            df_val = pd.read_csv(f\"features_aug_{split}_{model_name}_val.csv\")\n",
    "            df_test = pd.read_csv(f\"features_aug_{split}_{model_name}_test.csv\")\n",
    "\n",
    "            df_train[\"filename\"] = df_train[\"filename\"].astype(str)\n",
    "            df_val[\"filename\"] = df_val[\"filename\"].astype(str)\n",
    "            df_test[\"filename\"] = df_test[\"filename\"].astype(str)\n",
    "\n",
    "            X_train = df_train.drop(columns=[\"filename\"])\n",
    "            y_train = [0 if \"proper\" in fn.lower() else 1 for fn in df_train[\"filename\"]]\n",
    "\n",
    "            X_val = df_val.drop(columns=[\"filename\"])\n",
    "            y_val = [0 if \"proper\" in fn.lower() else 1 for fn in df_val[\"filename\"]]\n",
    "\n",
    "            X_test = df_test.drop(columns=[\"filename\"])\n",
    "            y_test = [0 if \"proper\" in fn.lower() else 1 for fn in df_test[\"filename\"]]\n",
    "\n",
    "            split_data[(split, model_name)] = {\n",
    "                \"X_train\": X_train, \"y_train\": y_train,\n",
    "                \"X_val\": X_val, \"y_val\": y_val,\n",
    "                \"X_test\": X_test, \"y_test\": y_test\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Skipping {split}-{model_name} due to error: {str(e)}\")\n",
    "\n",
    "metrics_scores = load_json(\"metrics_scores_aug_down.json\")\n",
    "best_params = load_json(\"best_hyperparams_aug_down.json\")\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, model_type):\n",
    "    if model_type == \"SVM\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 10, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "        }\n",
    "        model = SVC(**params, probability=True)\n",
    "    elif model_type == \"MLP\":\n",
    "        choice = trial.suggest_categorical(\"hidden_layer_sizes\", [\"100\", \"50_50\", \"200\"])\n",
    "        mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "        params = {\n",
    "            \"hidden_layer_sizes\": mapping[choice],\n",
    "            \"learning_rate_init\": trial.suggest_float(\"learning_rate_init\", 0.001, 0.1, log=True)\n",
    "        }\n",
    "        model = MLPClassifier(**params, max_iter=500, random_state=123)\n",
    "    elif model_type == \"LogisticRegression\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.01, 10, log=True),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\"]),\n",
    "        }\n",
    "        model = LogisticRegression(**params, random_state=123)\n",
    "    elif model_type == \"XGBoost\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        }\n",
    "        model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif model_type == \"LightGBM\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 60),\n",
    "        }\n",
    "        model = LGBMClassifier(**params, random_state=123)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_val)[:, 1]\n",
    "    best_thresh = find_best_threshold(y_val, probs)\n",
    "    preds = (probs >= best_thresh).astype(int)\n",
    "    report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "    trial.set_user_attr(\"threshold\", best_thresh)\n",
    "    return report[\"1\"][\"f1-score\"]\n",
    "\n",
    "def process_combination(ml_model_name, split_name, model_name, data):\n",
    "    key_json = f\"{ml_model_name}__{split_name}__{model_name}\"\n",
    "    model_path = f\"model_aug_down_{ml_model_name}_{split_name}_{model_name}.pkl\"\n",
    "    try:\n",
    "        logging.info(f\"[TRAINING] {key_json}\")\n",
    "        X_train, y_train = apply_downsampling(data[\"X_train\"], data[\"y_train\"])\n",
    "        X_val, y_val = data[\"X_val\"], data[\"y_val\"]\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=123))\n",
    "        study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val, ml_model_name), n_trials=15, n_jobs=18)\n",
    "        best_hyperparams = study.best_params\n",
    "        best_thresh = study.best_trial.user_attrs[\"threshold\"]\n",
    "\n",
    "        if ml_model_name == \"MLP\" and isinstance(best_hyperparams.get(\"hidden_layer_sizes\"), str):\n",
    "            mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "            best_hyperparams[\"hidden_layer_sizes\"] = mapping[best_hyperparams[\"hidden_layer_sizes\"]]\n",
    "\n",
    "        model = get_model_instance(ml_model_name)\n",
    "        model.set_params(**best_hyperparams)\n",
    "        model.fit(X_train, y_train)\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "        probs = model.predict_proba(X_val)[:, 1]\n",
    "        preds = (probs >= best_thresh).astype(int)\n",
    "        report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "\n",
    "        metrics_scores[key_json] = {\n",
    "            \"recall\": report[\"1\"][\"recall\"],\n",
    "            \"precision\": report[\"1\"][\"precision\"],\n",
    "            \"f1_score\": report[\"1\"][\"f1-score\"]\n",
    "        }\n",
    "\n",
    "        if ml_model_name not in best_params:\n",
    "            best_params[ml_model_name] = {}\n",
    "        best_params[ml_model_name][f\"{split_name}__{model_name}\"] = {\n",
    "            \"params\": best_hyperparams,\n",
    "            \"threshold\": float(best_thresh)\n",
    "        }\n",
    "\n",
    "        save_jsons()\n",
    "        logging.info(f\"[DONE] {key_json} with F1: {report['1']['f1-score']:.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[ERROR] {key_json} failed: {str(e)}\")\n",
    "        logging.error(traceback.format_exc())\n",
    "\n",
    "#run all\n",
    "ordered_ml_models = [\"MLP\", \"LogisticRegression\", \"XGBoost\", \"LightGBM\", \"SVM\"]\n",
    "tasks = [(ml, split, model, split_data[(split, model)]) for ml in ordered_ml_models for (split, model) in split_data]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=18) as executor:\n",
    "    futures = [executor.submit(process_combination, *task) for task in tasks]\n",
    "    for future in as_completed(futures):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c9e82-fcb5-45c5-81d2-610f304da205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsampling 1:3 + data augmentation\n",
    "log_file = \"train_log_aug_down3.txt\"\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "splits = [\n",
    "    \"customer1\", \"all_data\", \"broken\", \"capsules\", \"customer2\",\n",
    "    \"double\", \"minor_major\", \"oval_round_oblong\", \"tablets\"\n",
    "]\n",
    "allowed_models = [\n",
    "    \"convnext_base\", \"efficientnet_b3\", \"mobilenet_v3_large\",\n",
    "    \"vit_b_16\", \"densenet121\"\n",
    "]\n",
    "ml_model_names = [\"MLP\", \"LogisticRegression\", \"XGBoost\", \"LightGBM\", \"SVM\"]\n",
    "\n",
    "def get_model_instance(name):\n",
    "    if name == \"SVM\":\n",
    "        return SVC(probability=True)\n",
    "    elif name == \"MLP\":\n",
    "        return MLPClassifier(max_iter=500, random_state=123)\n",
    "    elif name == \"LogisticRegression\":\n",
    "        return LogisticRegression(random_state=123)\n",
    "    elif name == \"XGBoost\":\n",
    "        return XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif name == \"LightGBM\":\n",
    "        return LGBMClassifier(random_state=123)\n",
    "\n",
    "def load_json(path):\n",
    "    return json.load(open(path)) if os.path.exists(path) else {}\n",
    "\n",
    "def convert_for_json(obj):\n",
    "    return list(obj) if isinstance(obj, tuple) else obj\n",
    "\n",
    "def save_jsons():\n",
    "    with open(\"metrics_scores_aug_down3.json\", \"w\") as f:\n",
    "        json.dump(metrics_scores, f, indent=4)\n",
    "    with open(\"best_hyperparams_aug_down3.json\", \"w\") as f:\n",
    "        json.dump(best_params, f, indent=4, default=convert_for_json)\n",
    "\n",
    "def find_best_threshold(y_true, probs):\n",
    "    best_recall = 0\n",
    "    best_thresh = 0.5\n",
    "    for thresh in np.arange(0.1, 0.91, 0.05):\n",
    "        preds = (probs >= thresh).astype(int)\n",
    "        report = classification_report(y_true, preds, output_dict=True, zero_division=0)\n",
    "        recall = report[\"1\"][\"recall\"]\n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            best_thresh = thresh\n",
    "    return best_thresh\n",
    "\n",
    "def apply_downsampling(X, y, ratio=3):\n",
    "    df = X.copy()\n",
    "    df[\"label\"] = y\n",
    "    df_major = df[df[\"label\"] == 0]\n",
    "    df_minor = df[df[\"label\"] == 1]\n",
    "    n_major = min(len(df_major), len(df_minor) * ratio)\n",
    "    df_major_down = resample(df_major, replace=False, n_samples=n_major, random_state=123)\n",
    "    df_balanced = pd.concat([df_major_down, df_minor]).sample(frac=1, random_state=123)\n",
    "    y_balanced = df_balanced[\"label\"].tolist()\n",
    "    X_balanced = df_balanced.drop(columns=[\"label\"])\n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "#load features\n",
    "split_data = {}\n",
    "for split in splits:\n",
    "    for model_name in allowed_models:\n",
    "        try:\n",
    "            df_train = pd.read_csv(f\"features_aug_{split}_{model_name}_train.csv\")\n",
    "            df_val = pd.read_csv(f\"features_aug_{split}_{model_name}_val.csv\")\n",
    "            df_test = pd.read_csv(f\"features_aug_{split}_{model_name}_test.csv\")\n",
    "\n",
    "            df_train[\"filename\"] = df_train[\"filename\"].astype(str)\n",
    "            df_val[\"filename\"] = df_val[\"filename\"].astype(str)\n",
    "            df_test[\"filename\"] = df_test[\"filename\"].astype(str)\n",
    "\n",
    "            X_train = df_train.drop(columns=[\"filename\"])\n",
    "            y_train = [0 if \"proper\" in fn.lower() else 1 for fn in df_train[\"filename\"]]\n",
    "\n",
    "            X_val = df_val.drop(columns=[\"filename\"])\n",
    "            y_val = [0 if \"proper\" in fn.lower() else 1 for fn in df_val[\"filename\"]]\n",
    "\n",
    "            X_test = df_test.drop(columns=[\"filename\"])\n",
    "            y_test = [0 if \"proper\" in fn.lower() else 1 for fn in df_test[\"filename\"]]\n",
    "\n",
    "            split_data[(split, model_name)] = {\n",
    "                \"X_train\": X_train, \"y_train\": y_train,\n",
    "                \"X_val\": X_val, \"y_val\": y_val,\n",
    "                \"X_test\": X_test, \"y_test\": y_test\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Skipping {split}-{model_name} due to error: {str(e)}\")\n",
    "\n",
    "metrics_scores = load_json(\"metrics_scores_aug_down3.json\")\n",
    "best_params = load_json(\"best_hyperparams_aug_down3.json\")\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, model_type):\n",
    "    if model_type == \"SVM\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 10, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "        }\n",
    "        model = SVC(**params, probability=True)\n",
    "    elif model_type == \"MLP\":\n",
    "        choice = trial.suggest_categorical(\"hidden_layer_sizes\", [\"100\", \"50_50\", \"200\"])\n",
    "        mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "        params = {\n",
    "            \"hidden_layer_sizes\": mapping[choice],\n",
    "            \"learning_rate_init\": trial.suggest_float(\"learning_rate_init\", 0.001, 0.1, log=True)\n",
    "        }\n",
    "        model = MLPClassifier(**params, max_iter=500, random_state=123)\n",
    "    elif model_type == \"LogisticRegression\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.01, 10, log=True),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\"]),\n",
    "        }\n",
    "        model = LogisticRegression(**params, random_state=123)\n",
    "    elif model_type == \"XGBoost\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        }\n",
    "        model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif model_type == \"LightGBM\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 60),\n",
    "        }\n",
    "        model = LGBMClassifier(**params, random_state=123)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_val)[:, 1]\n",
    "    best_thresh = find_best_threshold(y_val, probs)\n",
    "    preds = (probs >= best_thresh).astype(int)\n",
    "    report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "    trial.set_user_attr(\"threshold\", best_thresh)\n",
    "    return report[\"1\"][\"f1-score\"]\n",
    "\n",
    "def process_combination(ml_model_name, split_name, model_name, data):\n",
    "    key_json = f\"{ml_model_name}__{split_name}__{model_name}\"\n",
    "    model_path = f\"model_aug_down3_{ml_model_name}_{split_name}_{model_name}.pkl\"\n",
    "    try:\n",
    "        logging.info(f\"[TRAINING] {key_json}\")\n",
    "        X_train, y_train = apply_downsampling(data[\"X_train\"], data[\"y_train\"], ratio=3)\n",
    "        X_val, y_val = data[\"X_val\"], data[\"y_val\"]\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=123))\n",
    "        study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val, ml_model_name), n_trials=5, n_jobs=18)\n",
    "        best_hyperparams = study.best_params\n",
    "        best_thresh = study.best_trial.user_attrs[\"threshold\"]\n",
    "\n",
    "        if ml_model_name == \"MLP\" and isinstance(best_hyperparams.get(\"hidden_layer_sizes\"), str):\n",
    "            mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "            best_hyperparams[\"hidden_layer_sizes\"] = mapping[best_hyperparams[\"hidden_layer_sizes\"]]\n",
    "\n",
    "        model = get_model_instance(ml_model_name)\n",
    "        model.set_params(**best_hyperparams)\n",
    "        model.fit(X_train, y_train)\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "        probs = model.predict_proba(X_val)[:, 1]\n",
    "        preds = (probs >= best_thresh).astype(int)\n",
    "        report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "\n",
    "        metrics_scores[key_json] = {\n",
    "            \"recall\": report[\"1\"][\"recall\"],\n",
    "            \"precision\": report[\"1\"][\"precision\"],\n",
    "            \"f1_score\": report[\"1\"][\"f1-score\"]\n",
    "        }\n",
    "\n",
    "        if ml_model_name not in best_params:\n",
    "            best_params[ml_model_name] = {}\n",
    "        best_params[ml_model_name][f\"{split_name}__{model_name}\"] = {\n",
    "            \"params\": best_hyperparams,\n",
    "            \"threshold\": float(best_thresh)\n",
    "        }\n",
    "\n",
    "        save_jsons()\n",
    "        logging.info(f\"[DONE] {key_json} with F1: {report['1']['f1-score']:.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[ERROR] {key_json} failed: {str(e)}\")\n",
    "        logging.error(traceback.format_exc())\n",
    "\n",
    "#run all\n",
    "ordered_ml_models = [\"MLP\", \"LogisticRegression\", \"XGBoost\", \"LightGBM\", \"SVM\"]\n",
    "tasks = [(ml, split, model, split_data[(split, model)]) for ml in ordered_ml_models for (split, model) in split_data]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=18) as executor:\n",
    "    futures = [executor.submit(process_combination, *task) for task in tasks]\n",
    "    for future in as_completed(futures):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff7b8a-bc3a-47e5-9dfe-e44b687e800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsampling 1:5 + data augmentation\n",
    "log_file = \"train_log_aug_down5.txt\"\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "splits = [\n",
    "    \"customer1\", \"all_data\", \"broken\", \"capsules\", \"customer2\",\n",
    "    \"double\", \"minor_major\", \"oval_round_oblong\", \"tablets\"\n",
    "]\n",
    "allowed_models = [\n",
    "    \"convnext_base\", \"efficientnet_b3\", \"mobilenet_v3_large\",\n",
    "    \"vit_b_16\", \"densenet121\"\n",
    "]\n",
    "ml_model_names = [\"MLP\", \"LogisticRegression\", \"XGBoost\", \"LightGBM\", \"SVM\"]\n",
    "\n",
    "def get_model_instance(name):\n",
    "    if name == \"SVM\":\n",
    "        return SVC(probability=True)\n",
    "    elif name == \"MLP\":\n",
    "        return MLPClassifier(max_iter=500, random_state=123)\n",
    "    elif name == \"LogisticRegression\":\n",
    "        return LogisticRegression(random_state=123)\n",
    "    elif name == \"XGBoost\":\n",
    "        return XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif name == \"LightGBM\":\n",
    "        return LGBMClassifier(random_state=123)\n",
    "\n",
    "def load_json(path):\n",
    "    return json.load(open(path)) if os.path.exists(path) else {}\n",
    "\n",
    "def convert_for_json(obj):\n",
    "    return list(obj) if isinstance(obj, tuple) else obj\n",
    "\n",
    "def save_jsons():\n",
    "    with open(\"metrics_scores_aug_down5.json\", \"w\") as f:\n",
    "        json.dump(metrics_scores, f, indent=4)\n",
    "    with open(\"best_hyperparams_aug_down5.json\", \"w\") as f:\n",
    "        json.dump(best_params, f, indent=4, default=convert_for_json)\n",
    "\n",
    "def find_best_threshold(y_true, probs):\n",
    "    best_recall = 0\n",
    "    best_thresh = 0.5\n",
    "    for thresh in np.arange(0.1, 0.91, 0.05):\n",
    "        preds = (probs >= thresh).astype(int)\n",
    "        report = classification_report(y_true, preds, output_dict=True, zero_division=0)\n",
    "        recall = report[\"1\"][\"recall\"]\n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            best_thresh = thresh\n",
    "    return best_thresh\n",
    "\n",
    "def apply_downsampling(X, y, ratio=5):\n",
    "    df = X.copy()\n",
    "    df[\"label\"] = y\n",
    "    df_major = df[df[\"label\"] == 0]\n",
    "    df_minor = df[df[\"label\"] == 1]\n",
    "    n_major = min(len(df_major), len(df_minor) * ratio)\n",
    "    df_major_down = resample(df_major, replace=False, n_samples=n_major, random_state=123)\n",
    "    df_balanced = pd.concat([df_major_down, df_minor]).sample(frac=1, random_state=123)\n",
    "    y_balanced = df_balanced[\"label\"].tolist()\n",
    "    X_balanced = df_balanced.drop(columns=[\"label\"])\n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "#load features\n",
    "split_data = {}\n",
    "for split in splits:\n",
    "    for model_name in allowed_models:\n",
    "        try:\n",
    "            df_train = pd.read_csv(f\"features_aug_{split}_{model_name}_train.csv\")\n",
    "            df_val = pd.read_csv(f\"features_aug_{split}_{model_name}_val.csv\")\n",
    "            df_test = pd.read_csv(f\"features_aug_{split}_{model_name}_test.csv\")\n",
    "\n",
    "            df_train[\"filename\"] = df_train[\"filename\"].astype(str)\n",
    "            df_val[\"filename\"] = df_val[\"filename\"].astype(str)\n",
    "            df_test[\"filename\"] = df_test[\"filename\"].astype(str)\n",
    "\n",
    "            X_train = df_train.drop(columns=[\"filename\"])\n",
    "            y_train = [0 if \"proper\" in fn.lower() else 1 for fn in df_train[\"filename\"]]\n",
    "\n",
    "            X_val = df_val.drop(columns=[\"filename\"])\n",
    "            y_val = [0 if \"proper\" in fn.lower() else 1 for fn in df_val[\"filename\"]]\n",
    "\n",
    "            X_test = df_test.drop(columns=[\"filename\"])\n",
    "            y_test = [0 if \"proper\" in fn.lower() else 1 for fn in df_test[\"filename\"]]\n",
    "\n",
    "            split_data[(split, model_name)] = {\n",
    "                \"X_train\": X_train, \"y_train\": y_train,\n",
    "                \"X_val\": X_val, \"y_val\": y_val,\n",
    "                \"X_test\": X_test, \"y_test\": y_test\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Skipping {split}-{model_name} due to error: {str(e)}\")\n",
    "\n",
    "metrics_scores = load_json(\"metrics_scores_aug_down5.json\")\n",
    "best_params = load_json(\"best_hyperparams_aug_down5.json\")\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, model_type):\n",
    "    if model_type == \"SVM\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 10, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "        }\n",
    "        model = SVC(**params, probability=True)\n",
    "    elif model_type == \"MLP\":\n",
    "        choice = trial.suggest_categorical(\"hidden_layer_sizes\", [\"100\", \"50_50\", \"200\"])\n",
    "        mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "        params = {\n",
    "            \"hidden_layer_sizes\": mapping[choice],\n",
    "            \"learning_rate_init\": trial.suggest_float(\"learning_rate_init\", 0.001, 0.1, log=True)\n",
    "        }\n",
    "        model = MLPClassifier(**params, max_iter=500, random_state=123)\n",
    "    elif model_type == \"LogisticRegression\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.01, 10, log=True),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\"]),\n",
    "        }\n",
    "        model = LogisticRegression(**params, random_state=123)\n",
    "    elif model_type == \"XGBoost\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        }\n",
    "        model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif model_type == \"LightGBM\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 60),\n",
    "        }\n",
    "        model = LGBMClassifier(**params, random_state=123)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_val)[:, 1]\n",
    "    best_thresh = find_best_threshold(y_val, probs)\n",
    "    preds = (probs >= best_thresh).astype(int)\n",
    "    report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "    trial.set_user_attr(\"threshold\", best_thresh)\n",
    "    return report[\"1\"][\"f1-score\"]\n",
    "\n",
    "def process_combination(ml_model_name, split_name, model_name, data):\n",
    "    key_json = f\"{ml_model_name}__{split_name}__{model_name}\"\n",
    "    model_path = f\"model_aug_down5_{ml_model_name}_{split_name}_{model_name}.pkl\"\n",
    "    try:\n",
    "        logging.info(f\"[TRAINING] {key_json}\")\n",
    "        X_train, y_train = apply_downsampling(data[\"X_train\"], data[\"y_train\"], ratio=5)\n",
    "        X_val, y_val = data[\"X_val\"], data[\"y_val\"]\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=123))\n",
    "        study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val, ml_model_name), n_trials=15, n_jobs=18)\n",
    "        best_hyperparams = study.best_params\n",
    "        best_thresh = study.best_trial.user_attrs[\"threshold\"]\n",
    "\n",
    "        if ml_model_name == \"MLP\" and isinstance(best_hyperparams.get(\"hidden_layer_sizes\"), str):\n",
    "            mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "            best_hyperparams[\"hidden_layer_sizes\"] = mapping[best_hyperparams[\"hidden_layer_sizes\"]]\n",
    "\n",
    "        model = get_model_instance(ml_model_name)\n",
    "        model.set_params(**best_hyperparams)\n",
    "        model.fit(X_train, y_train)\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "        probs = model.predict_proba(X_val)[:, 1]\n",
    "        preds = (probs >= best_thresh).astype(int)\n",
    "        report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "\n",
    "        metrics_scores[key_json] = {\n",
    "            \"recall\": report[\"1\"][\"recall\"],\n",
    "            \"precision\": report[\"1\"][\"precision\"],\n",
    "            \"f1_score\": report[\"1\"][\"f1-score\"]\n",
    "        }\n",
    "\n",
    "        if ml_model_name not in best_params:\n",
    "            best_params[ml_model_name] = {}\n",
    "        best_params[ml_model_name][f\"{split_name}__{model_name}\"] = {\n",
    "            \"params\": best_hyperparams,\n",
    "            \"threshold\": float(best_thresh)\n",
    "        }\n",
    "\n",
    "        save_jsons()\n",
    "        logging.info(f\"[DONE] {key_json} with F1: {report['1']['f1-score']:.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[ERROR] {key_json} failed: {str(e)}\")\n",
    "        logging.error(traceback.format_exc())\n",
    "\n",
    "#run all\n",
    "ordered_ml_models = [\"MLP\", \"LogisticRegression\", \"XGBoost\", \"LightGBM\", \"SVM\"]\n",
    "tasks = [(ml, split, model, split_data[(split, model)]) for ml in ordered_ml_models for (split, model) in split_data]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(process_combination, *task) for task in tasks]\n",
    "    for future in as_completed(futures):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0fac62-ba0a-4e98-b4d6-84a0247b4dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE 1:3\n",
    "logging.basicConfig(filename=\"train_log_smote3.txt\", level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "splits = [\n",
    "    \"customer1\", \"all_data\", \"broken\", \"capsules\", \"customer2\",\n",
    "    \"double\", \"minor_major\", \"oval_round_oblong\", \"tablets\"\n",
    "]\n",
    "allowed_models = [\n",
    "    \"convnext_base\", \"efficientnet_b3\", \"mobilenet_v3_large\",\n",
    "    \"vit_b_16\", \"densenet121\"\n",
    "]\n",
    "ordered_ml_models = [\"MLP\", \"LogisticRegression\", \"XGBoost\", \"LightGBM\", \"SVM\"]\n",
    "split_info_dir = \"splits_info\"\n",
    "\n",
    "def get_model_instance(name):\n",
    "    if name == \"SVM\":\n",
    "        return SVC(probability=True)\n",
    "    elif name == \"MLP\":\n",
    "        return MLPClassifier(max_iter=500, random_state=123)\n",
    "    elif name == \"LogisticRegression\":\n",
    "        return LogisticRegression(random_state=123)\n",
    "    elif name == \"XGBoost\":\n",
    "        return XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif name == \"LightGBM\":\n",
    "        return LGBMClassifier(random_state=123)\n",
    "\n",
    "def convert_for_json(obj):\n",
    "    return list(obj) if isinstance(obj, tuple) else obj\n",
    "\n",
    "def save_jsons():\n",
    "    with open(\"metrics_scores_smote3.json\", \"w\") as f:\n",
    "        json.dump(metrics_scores, f, indent=4)\n",
    "    with open(\"best_hyperparams_smote3.json\", \"w\") as f:\n",
    "        json.dump(best_params, f, indent=4, default=convert_for_json)\n",
    "\n",
    "def find_best_threshold(y_true, probs):\n",
    "    best_recall = 0\n",
    "    best_thresh = 0.5\n",
    "    for thresh in np.arange(0.1, 0.91, 0.05):\n",
    "        preds = (probs >= thresh).astype(int)\n",
    "        report = classification_report(y_true, preds, output_dict=True, zero_division=0)\n",
    "        recall = report[\"1\"][\"recall\"]\n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            best_thresh = thresh\n",
    "    return best_thresh\n",
    "\n",
    "def apply_smote_oversampling(X, y):\n",
    "    smote = SMOTE(sampling_strategy=0.33, random_state=123)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "#load features \n",
    "all_features = {}\n",
    "for model_name in allowed_models:\n",
    "    path = f\"features_{model_name}.csv\"\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        df[\"filename\"] = df[\"filename\"].astype(str)\n",
    "        all_features[model_name] = df\n",
    "    else:\n",
    "        logging.warning(f\"Missing features: {path}\")\n",
    "\n",
    "#split_data\n",
    "split_data = {}\n",
    "for split in splits:\n",
    "    split_path = os.path.join(split_info_dir, split)\n",
    "    try:\n",
    "        with open(os.path.join(split_path, \"train.txt\")) as f:\n",
    "            train_files = {line.strip() for line in f}\n",
    "        with open(os.path.join(split_path, \"val.txt\")) as f:\n",
    "            val_files = {line.strip() for line in f}\n",
    "        with open(os.path.join(split_path, \"test.txt\")) as f:\n",
    "            test_files = {line.strip() for line in f}\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Skipping split {split}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "    for model_name, df in all_features.items():\n",
    "        df_train = df[df[\"filename\"].isin(train_files)]\n",
    "        df_val = df[df[\"filename\"].isin(val_files)]\n",
    "        df_test = df[df[\"filename\"].isin(test_files)]\n",
    "\n",
    "        X_train = df_train.drop(columns=[\"filename\"])\n",
    "        y_train = [0 if \"proper\" in fn.lower() else 1 for fn in df_train[\"filename\"]]\n",
    "\n",
    "        X_val = df_val.drop(columns=[\"filename\"])\n",
    "        y_val = [0 if \"proper\" in fn.lower() else 1 for fn in df_val[\"filename\"]]\n",
    "\n",
    "        X_test = df_test.drop(columns=[\"filename\"])\n",
    "        y_test = [0 if \"proper\" in fn.lower() else 1 for fn in df_test[\"filename\"]]\n",
    "\n",
    "        split_data[(split, model_name)] = {\n",
    "            \"X_train\": X_train, \"y_train\": y_train,\n",
    "            \"X_val\": X_val, \"y_val\": y_val,\n",
    "            \"X_test\": X_test, \"y_test\": y_test\n",
    "        }\n",
    "\n",
    "#load jsons\n",
    "metrics_scores = json.load(open(\"metrics_scores_smote3.json\")) if os.path.exists(\"metrics_scores_smote3.json\") else {}\n",
    "best_params = json.load(open(\"best_hyperparams_smote3.json\")) if os.path.exists(\"best_hyperparams_smote3.json\") else {}\n",
    "\n",
    "#objective function \n",
    "def objective(trial, X_train, y_train, X_val, y_val, model_type):\n",
    "    if model_type == \"SVM\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 10, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "        }\n",
    "        model = SVC(**params, probability=True)\n",
    "    elif model_type == \"MLP\":\n",
    "        choice = trial.suggest_categorical(\"hidden_layer_sizes\", [\"100\", \"50_50\", \"200\"])\n",
    "        mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "        params = {\n",
    "            \"hidden_layer_sizes\": mapping[choice],\n",
    "            \"learning_rate_init\": trial.suggest_float(\"learning_rate_init\", 0.001, 0.1, log=True)\n",
    "        }\n",
    "        model = MLPClassifier(**params, max_iter=500, random_state=123)\n",
    "    elif model_type == \"LogisticRegression\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.01, 10, log=True),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\"]),\n",
    "        }\n",
    "        model = LogisticRegression(**params, random_state=123)\n",
    "    elif model_type == \"XGBoost\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        }\n",
    "        model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif model_type == \"LightGBM\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 60),\n",
    "        }\n",
    "        model = LGBMClassifier(**params, random_state=123)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_val)[:, 1]\n",
    "    best_thresh = find_best_threshold(y_val, probs)\n",
    "    preds = (probs >= best_thresh).astype(int)\n",
    "    report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "    trial.set_user_attr(\"threshold\", best_thresh)\n",
    "    return report[\"1\"][\"f1-score\"]\n",
    "\n",
    "#training wrapper\n",
    "def process_combination(ml_model_name, split_name, model_name, data):\n",
    "    key_json = f\"{ml_model_name}__{split_name}__{model_name}\"\n",
    "    model_path = f\"model_smote3_{ml_model_name}_{split_name}_{model_name}.pkl\"\n",
    "    try:\n",
    "        logging.info(f\"[TRAINING] {key_json}\")\n",
    "        X_train, y_train = apply_smote_oversampling(data[\"X_train\"], data[\"y_train\"])\n",
    "        X_val, y_val = data[\"X_val\"], data[\"y_val\"]\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=123))\n",
    "        study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val, ml_model_name), n_trials=15, n_jobs=18)\n",
    "        best_hyperparams = study.best_params\n",
    "        best_thresh = study.best_trial.user_attrs[\"threshold\"]\n",
    "\n",
    "        if ml_model_name == \"MLP\" and isinstance(best_hyperparams.get(\"hidden_layer_sizes\"), str):\n",
    "            mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "            best_hyperparams[\"hidden_layer_sizes\"] = mapping[best_hyperparams[\"hidden_layer_sizes\"]]\n",
    "\n",
    "        model = get_model_instance(ml_model_name)\n",
    "        model.set_params(**best_hyperparams)\n",
    "        model.fit(X_train, y_train)\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "        probs = model.predict_proba(X_val)[:, 1]\n",
    "        preds = (probs >= best_thresh).astype(int)\n",
    "        report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "\n",
    "        metrics_scores[key_json] = {\n",
    "            \"recall\": report[\"1\"][\"recall\"],\n",
    "            \"precision\": report[\"1\"][\"precision\"],\n",
    "            \"f1_score\": report[\"1\"][\"f1-score\"]\n",
    "        }\n",
    "\n",
    "        if ml_model_name not in best_params:\n",
    "            best_params[ml_model_name] = {}\n",
    "        best_params[ml_model_name][f\"{split_name}__{model_name}\"] = {\n",
    "            \"params\": best_hyperparams,\n",
    "            \"threshold\": float(best_thresh)\n",
    "        }\n",
    "\n",
    "        save_jsons()\n",
    "        logging.info(f\"[DONE] {key_json} with F1: {report['1']['f1-score']:.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[ERROR] {key_json} failed: {str(e)}\")\n",
    "        logging.error(traceback.format_exc())\n",
    "\n",
    "#training\n",
    "tasks = [(ml, split, model, split_data[(split, model)])\n",
    "         for ml in ordered_ml_models for (split, model) in split_data]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(process_combination, *task) for task in tasks]\n",
    "    for future in as_completed(futures):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01984f2c-1ea8-421b-acec-6e06a1753a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE 1:5\n",
    "logging.basicConfig(filename=\"train_log_smote5.txt\", level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "splits = [\n",
    "    \"customer1\", \"all_data\", \"broken\", \"capsules\", \"customer2\",\n",
    "    \"double\", \"minor_major\", \"oval_round_oblong\", \"tablets\"\n",
    "]\n",
    "allowed_models = [\n",
    "    \"convnext_base\", \"efficientnet_b3\", \"mobilenet_v3_large\",\n",
    "    \"vit_b_16\", \"densenet121\"\n",
    "]\n",
    "ordered_ml_models = [\"MLP\", \"LogisticRegression\", \"XGBoost\", \"LightGBM\", \"SVM\"]\n",
    "split_info_dir = \"splits_info\"\n",
    "\n",
    "def get_model_instance(name):\n",
    "    if name == \"SVM\":\n",
    "        return SVC(probability=True)\n",
    "    elif name == \"MLP\":\n",
    "        return MLPClassifier(max_iter=500, random_state=123)\n",
    "    elif name == \"LogisticRegression\":\n",
    "        return LogisticRegression(random_state=123)\n",
    "    elif name == \"XGBoost\":\n",
    "        return XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif name == \"LightGBM\":\n",
    "        return LGBMClassifier(random_state=123)\n",
    "\n",
    "def convert_for_json(obj):\n",
    "    return list(obj) if isinstance(obj, tuple) else obj\n",
    "\n",
    "def save_jsons():\n",
    "    with open(\"metrics_scores_smote5.json\", \"w\") as f:\n",
    "        json.dump(metrics_scores, f, indent=4)\n",
    "    with open(\"best_hyperparams_smote5.json\", \"w\") as f:\n",
    "        json.dump(best_params, f, indent=4, default=convert_for_json)\n",
    "\n",
    "def find_best_threshold(y_true, probs):\n",
    "    best_recall = 0\n",
    "    best_thresh = 0.5\n",
    "    for thresh in np.arange(0.1, 0.91, 0.05):\n",
    "        preds = (probs >= thresh).astype(int)\n",
    "        report = classification_report(y_true, preds, output_dict=True, zero_division=0)\n",
    "        recall = report[\"1\"][\"recall\"]\n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            best_thresh = thresh\n",
    "    return best_thresh\n",
    "\n",
    "def apply_smote_oversampling(X, y):\n",
    "    smote = SMOTE(sampling_strategy=0.2, random_state=123)  # 1:5 ratio = 0.2\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "#load features\n",
    "all_features = {}\n",
    "for model_name in allowed_models:\n",
    "    path = f\"features_{model_name}.csv\"\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        df[\"filename\"] = df[\"filename\"].astype(str)\n",
    "        all_features[model_name] = df\n",
    "    else:\n",
    "        logging.warning(f\"Missing features: {path}\")\n",
    "\n",
    "#split_data\n",
    "split_data = {}\n",
    "for split in splits:\n",
    "    split_path = os.path.join(split_info_dir, split)\n",
    "    try:\n",
    "        with open(os.path.join(split_path, \"train.txt\")) as f:\n",
    "            train_files = {line.strip() for line in f}\n",
    "        with open(os.path.join(split_path, \"val.txt\")) as f:\n",
    "            val_files = {line.strip() for line in f}\n",
    "        with open(os.path.join(split_path, \"test.txt\")) as f:\n",
    "            test_files = {line.strip() for line in f}\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Skipping split {split}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "    for model_name, df in all_features.items():\n",
    "        df_train = df[df[\"filename\"].isin(train_files)]\n",
    "        df_val = df[df[\"filename\"].isin(val_files)]\n",
    "        df_test = df[df[\"filename\"].isin(test_files)]\n",
    "\n",
    "        X_train = df_train.drop(columns=[\"filename\"])\n",
    "        y_train = [0 if \"proper\" in fn.lower() else 1 for fn in df_train[\"filename\"]]\n",
    "\n",
    "        X_val = df_val.drop(columns=[\"filename\"])\n",
    "        y_val = [0 if \"proper\" in fn.lower() else 1 for fn in df_val[\"filename\"]]\n",
    "\n",
    "        X_test = df_test.drop(columns=[\"filename\"])\n",
    "        y_test = [0 if \"proper\" in fn.lower() else 1 for fn in df_test[\"filename\"]]\n",
    "\n",
    "        split_data[(split, model_name)] = {\n",
    "            \"X_train\": X_train, \"y_train\": y_train,\n",
    "            \"X_val\": X_val, \"y_val\": y_val,\n",
    "            \"X_test\": X_test, \"y_test\": y_test\n",
    "        }\n",
    "\n",
    "#load jsons\n",
    "metrics_scores = json.load(open(\"metrics_scores_smote5.json\")) if os.path.exists(\"metrics_scores_smote5.json\") else {}\n",
    "best_params = json.load(open(\"best_hyperparams_smote5.json\")) if os.path.exists(\"best_hyperparams_smote5.json\") else {}\n",
    "\n",
    "#objective function \n",
    "def objective(trial, X_train, y_train, X_val, y_val, model_type):\n",
    "    if model_type == \"SVM\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 10, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "        }\n",
    "        model = SVC(**params, probability=True)\n",
    "    elif model_type == \"MLP\":\n",
    "        choice = trial.suggest_categorical(\"hidden_layer_sizes\", [\"100\", \"50_50\", \"200\"])\n",
    "        mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "        params = {\n",
    "            \"hidden_layer_sizes\": mapping[choice],\n",
    "            \"learning_rate_init\": trial.suggest_float(\"learning_rate_init\", 0.001, 0.1, log=True)\n",
    "        }\n",
    "        model = MLPClassifier(**params, max_iter=500, random_state=123)\n",
    "    elif model_type == \"LogisticRegression\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.01, 10, log=True),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\"]),\n",
    "        }\n",
    "        model = LogisticRegression(**params, random_state=123)\n",
    "    elif model_type == \"XGBoost\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        }\n",
    "        model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss', random_state=123)\n",
    "    elif model_type == \"LightGBM\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 60),\n",
    "        }\n",
    "        model = LGBMClassifier(**params, random_state=123)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_val)[:, 1]\n",
    "    best_thresh = find_best_threshold(y_val, probs)\n",
    "    preds = (probs >= best_thresh).astype(int)\n",
    "    report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "    trial.set_user_attr(\"threshold\", best_thresh)\n",
    "    return report[\"1\"][\"f1-score\"]\n",
    "\n",
    "#training wrapper\n",
    "def process_combination(ml_model_name, split_name, model_name, data):\n",
    "    key_json = f\"{ml_model_name}__{split_name}__{model_name}\"\n",
    "    model_path = f\"model_smote5_{ml_model_name}_{split_name}_{model_name}.pkl\"\n",
    "    try:\n",
    "        logging.info(f\"[TRAINING] {key_json}\")\n",
    "        X_train, y_train = apply_smote_oversampling(data[\"X_train\"], data[\"y_train\"])\n",
    "        X_val, y_val = data[\"X_val\"], data[\"y_val\"]\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=123))\n",
    "        study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val, ml_model_name), n_trials=15, n_jobs=18)\n",
    "        best_hyperparams = study.best_params\n",
    "        best_thresh = study.best_trial.user_attrs[\"threshold\"]\n",
    "\n",
    "        if ml_model_name == \"MLP\" and isinstance(best_hyperparams.get(\"hidden_layer_sizes\"), str):\n",
    "            mapping = {\"100\": (100,), \"50_50\": (50, 50), \"200\": (200,)}\n",
    "            best_hyperparams[\"hidden_layer_sizes\"] = mapping[best_hyperparams[\"hidden_layer_sizes\"]]\n",
    "\n",
    "        model = get_model_instance(ml_model_name)\n",
    "        model.set_params(**best_hyperparams)\n",
    "        model.fit(X_train, y_train)\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "        probs = model.predict_proba(X_val)[:, 1]\n",
    "        preds = (probs >= best_thresh).astype(int)\n",
    "        report = classification_report(y_val, preds, output_dict=True, zero_division=0)\n",
    "\n",
    "        metrics_scores[key_json] = {\n",
    "            \"recall\": report[\"1\"][\"recall\"],\n",
    "            \"precision\": report[\"1\"][\"precision\"],\n",
    "            \"f1_score\": report[\"1\"][\"f1-score\"]\n",
    "        }\n",
    "\n",
    "        if ml_model_name not in best_params:\n",
    "            best_params[ml_model_name] = {}\n",
    "        best_params[ml_model_name][f\"{split_name}__{model_name}\"] = {\n",
    "            \"params\": best_hyperparams,\n",
    "            \"threshold\": float(best_thresh)\n",
    "        }\n",
    "\n",
    "        save_jsons()\n",
    "        logging.info(f\"[DONE] {key_json} with F1: {report['1']['f1-score']:.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[ERROR] {key_json} failed: {str(e)}\")\n",
    "        logging.error(traceback.format_exc())\n",
    "\n",
    "#training\n",
    "tasks = [(ml, split, model, split_data[(split, model)])\n",
    "         for ml in ordered_ml_models for (split, model) in split_data]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(process_combination, *task) for task in tasks]\n",
    "    for future in as_completed(futures):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c767d7-e444-4da4-8e0c-e18ee6b51009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "threshold_files = sorted(glob(\"best_hyperparams_*.json\"))\n",
    "model_files = sorted(glob(\"model_*.pkl\"))\n",
    "metrics_all = []\n",
    "\n",
    "splits = [\n",
    "    \"customer1\", \"all_data\", \"broken\", \"capsules\", \"customer2\",\n",
    "    \"double\", \"minor_major\", \"oval_round_oblong\", \"tablets\"\n",
    "]\n",
    "\n",
    "#load features and labels for all splits and models\n",
    "def load_test_features(split, model_name):\n",
    "    path = f\"features_{split}_{model_name}_test.csv\"\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        X = df.drop(columns=[\"filename\"])\n",
    "        y = [0 if \"proper\" in fn.lower() else 1 for fn in df[\"filename\"]]\n",
    "        return X, y\n",
    "    return None, None\n",
    "\n",
    "for model_file in model_files:\n",
    "    filename = os.path.basename(model_file)\n",
    "    parts = filename.replace(\".pkl\", \"\").split(\"_\")\n",
    "    \n",
    "    strategy = parts[1] if parts[0] == \"model\" else parts[0]\n",
    "    clf = parts[-3]\n",
    "    split = parts[-2]\n",
    "    model_name = parts[-1]\n",
    "    \n",
    "    if split not in splits:\n",
    "        continue\n",
    "\n",
    "    #load model \n",
    "    try:\n",
    "        model = joblib.load(model_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model: {filename} â€” {e}\")\n",
    "        continue\n",
    "\n",
    "    # find and load a threshold\n",
    "    matched_jsons = [f for f in threshold_files if strategy in f]\n",
    "    threshold = 0.5\n",
    "    for jfile in matched_jsons:\n",
    "        with open(jfile) as f:\n",
    "            best_params = json.load(f)\n",
    "        if clf in best_params and f\"{split}__{model_name}\" in best_params[clf]:\n",
    "            threshold = best_params[clf][f\"{split}__{model_name}\"].get(\"threshold\", 0.5)\n",
    "            break\n",
    "\n",
    "    #load test data\n",
    "    X_test, y_test = load_test_features(split, model_name)\n",
    "    if X_test is None:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        probs = model.predict_proba(X_test)[:, 1]\n",
    "        preds = (probs >= threshold).astype(int)\n",
    "        report = classification_report(y_test, preds, output_dict=True, zero_division=0)\n",
    "        metrics_all.append({\n",
    "            \"strategy\": strategy,\n",
    "            \"split\": split,\n",
    "            \"cnn\": model_name,\n",
    "            \"classifier\": clf,\n",
    "            \"precision\": report[\"1\"][\"precision\"],\n",
    "            \"recall\": report[\"1\"][\"recall\"],\n",
    "            \"f1_score\": report[\"1\"][\"f1-score\"],\n",
    "            \"accuracy\": report[\"1\"][\"accuracy\"]\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Failed prediction for {filename}: {e}\")\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_all)\n",
    "df_metrics.to_csv(\"test_results_all_models.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
